{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Analysis System with AgentNeo Integration\n",
    "\n",
    "This Jupyter notebook demonstrates the integration of AgentNeo, a powerful tracing and monitoring tool, with a financial analysis system. AgentNeo provides seamless tracing capabilities for both function calls and AI model interactions, allowing for comprehensive analysis and debugging of complex systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from agentneo import AgentNeo, Tracer, Evaluation\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(r\"E:\\Agent_hackathon\\AgentNeo\\examples\\.env\")\n",
    "\n",
    "# Initialize OpenAI API\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinancialAnalysisSystem Class\n",
    "\n",
    "Now, let's define our `FinancialAnalysisSystem` class with AgentNeo integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project 'financial_analysis_project2' found.\n",
      "Tracing Started.\n"
     ]
    }
   ],
   "source": [
    "# Initialize AgentNeo session\n",
    "neo_session = AgentNeo(session_name=\"financial_analysis_session2\")\n",
    "\n",
    "# Create project\n",
    "neo_session.create_project(project_name=\"financial_analysis_project2\")\n",
    "\n",
    "# Start tracing\n",
    "tracer = Tracer(session=neo_session)\n",
    "tracer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialAnalysisSystem:\n",
    "    def __init__(self):\n",
    "        self.stock_data = {}\n",
    "        self.news_sentiment = {}\n",
    "        self.economic_indicators = {}\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_stock_data\")\n",
    "    def fetch_stock_data(self, symbol):\n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"price\": round(random.uniform(50, 500), 2),\n",
    "            \"change\": round(random.uniform(-5, 5), 2),\n",
    "        }\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_news_articles\")\n",
    "    def fetch_news_articles(self, company):\n",
    "        return [\n",
    "            f\"{company} announces new product line\",\n",
    "            f\"{company} reports quarterly earnings\",\n",
    "            f\"{company} faces regulatory scrutiny\",\n",
    "        ]\n",
    "\n",
    "    @tracer.trace_tool(name=\"analyze_sentiment\")\n",
    "    def analyze_sentiment(self, text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_economic_indicators\")\n",
    "    def fetch_economic_indicators(self):\n",
    "        return {\n",
    "            \"gdp_growth\": round(random.uniform(-2, 5), 2),\n",
    "            \"unemployment_rate\": round(random.uniform(3, 10), 2),\n",
    "            \"inflation_rate\": round(random.uniform(0, 5), 2),\n",
    "        }\n",
    "\n",
    "    @tracer.trace_llm(name=\"analyze_market_conditions\")\n",
    "    def analyze_market_conditions(self, stock_data, sentiment, economic_indicators):\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following market conditions and provide a brief market outlook:\n",
    "        Stock: {stock_data['symbol']} at ${stock_data['price']} (change: {stock_data['change']}%)\n",
    "        News Sentiment: {sentiment}\n",
    "        Economic Indicators:\n",
    "        - GDP Growth: {economic_indicators['gdp_growth']}%\n",
    "        - Unemployment Rate: {economic_indicators['unemployment_rate']}%\n",
    "        - Inflation Rate: {economic_indicators['inflation_rate']}%\n",
    "        \"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    @tracer.trace_llm(name=\"generate_investment_recommendation\")\n",
    "    def generate_investment_recommendation(self, market_outlook, risk_tolerance):\n",
    "        prompt = f\"\"\"\n",
    "        Based on the following market outlook and investor risk tolerance,\n",
    "        provide a specific investment recommendation:\n",
    "        Market Outlook: {market_outlook}\n",
    "        Investor Risk Tolerance: {risk_tolerance}\n",
    "        \"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    @tracer.trace_agent(name=\"FinancialAdvisorAgent\")\n",
    "    def financial_advisor_agent(self, stock_symbol, risk_tolerance):\n",
    "        self.stock_data = self.fetch_stock_data(stock_symbol)\n",
    "        news_articles = self.fetch_news_articles(stock_symbol)\n",
    "        sentiment_scores = [self.analyze_sentiment(article) for article in news_articles]\n",
    "        self.news_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        self.economic_indicators = self.fetch_economic_indicators()\n",
    "        market_outlook = self.analyze_market_conditions(\n",
    "            self.stock_data, self.news_sentiment, self.economic_indicators\n",
    "        )\n",
    "        recommendation = self.generate_investment_recommendation(market_outlook, risk_tolerance)\n",
    "        return recommendation\n",
    "\n",
    "    def run_analysis(self, stock_symbol, risk_tolerance):\n",
    "        recommendation = self.financial_advisor_agent(stock_symbol, risk_tolerance)\n",
    "        print(f\"\\nAnalysis for {stock_symbol}:\")\n",
    "        print(f\"Stock Data: {self.stock_data}\")\n",
    "        print(f\"News Sentiment: {self.news_sentiment}\")\n",
    "        print(f\"Economic Indicators: {self.economic_indicators}\")\n",
    "        print(f\"\\nInvestment Recommendation:\\n{recommendation}\")\n",
    "        if \"buy\" in recommendation.lower():\n",
    "            self.execute_buy_order(stock_symbol)\n",
    "        elif \"sell\" in recommendation.lower():\n",
    "            self.execute_sell_order(stock_symbol)\n",
    "        else:\n",
    "            print(\"No action taken based on the current recommendation.\")\n",
    "\n",
    "    @tracer.trace_tool(name=\"execute_buy_order\")\n",
    "    def execute_buy_order(self, symbol):\n",
    "        print(f\"Executing buy order for {symbol}\")\n",
    "\n",
    "    @tracer.trace_tool(name=\"execute_sell_order\")\n",
    "    def execute_sell_order(self, symbol):\n",
    "        print(f\"Executing sell order for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Analysis\n",
    "\n",
    "Now let's create an instance of our `FinancialAnalysisSystem` and run an analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:agentneo.tracing.agent_tracer:Successfully updated and committed AgentCallModel with id 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for AAPL:\n",
      "Stock Data: {'symbol': 'AAPL', 'price': 353.24, 'change': -1.08}\n",
      "News Sentiment: 0.04545454545454545\n",
      "Economic Indicators: {'gdp_growth': 1.18, 'unemployment_rate': 5.0, 'inflation_rate': 1.14}\n",
      "\n",
      "Investment Recommendation:\n",
      "Given the provided market outlook for Apple Inc. (AAPL), which highlights a recent decline in stock price and a slightly positive news sentiment, coupled with your moderate risk tolerance, a specific investment recommendation would entail a balanced approach that combines growth with a degree of caution. Here's the strategy:\n",
      "\n",
      "### Recommended Investment Strategy: Buy and Hold with Monitoring\n",
      "\n",
      "1. **Initial Purchase**: Considering the slight positive bias in news sentiment and your moderate risk tolerance, initiating a modest position in AAPL could be a prudent move. The recent dip in stock price may present a buying opportunity, assuming you believe in the company's long-term growth prospects. Apple, as a leading technology company, has shown resilience and innovation over the years, which could translate to stock recovery and growth over time.\n",
      "\n",
      "2. **Diversification**: To mitigate the risks associated with investing in a single stock and to balance your investment portfolio, consider diversifying across different sectors and asset classes. This may include bonds, ETFs, and stocks in\n",
      "Executing buy order for AAPL\n",
      "Tracing Completed.\n",
      "Data saved to the database and JSON file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of FinancialAnalysisSystem\n",
    "analysis_system = FinancialAnalysisSystem()\n",
    "\n",
    "# Run an analysis for Apple stock with moderate risk tolerance\n",
    "analysis_system.run_analysis(\"AAPL\", \"moderate\")\n",
    "\n",
    "# Stop the tracer when analysis is complete\n",
    "tracer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m12:36:44 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:36:47 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:36:47 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:36:49 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:36:49 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:36:54 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:36:54 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:36:57 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:36:57 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:03 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:03 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:04 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:04 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:09 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:09 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:10 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:10 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:12 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:12 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:13 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:13 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:14 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:14 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:15 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:15 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:16 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:16 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:18 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:18 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:19 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:19 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:21 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:21 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:21 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:21 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:22 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:22 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:24 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:24 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:25 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:25 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:26 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:26 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:28 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:28 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:29 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:29 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:31 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:31 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:32 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:32 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:34 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:34 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:36 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:36 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:37 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:37 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:39 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:39 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:41 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:41 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:42 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:42 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:44 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m12:37:44 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m12:37:47 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "exe = Evaluation(session=neo_session, trace_id=tracer.trace_id)\n",
    "\n",
    "# run a single metric\n",
    "exe.evaluate(metric_list=['goal_decomposition_efficiency', \n",
    "                         'goal_fulfillment_rate', \n",
    "                         'tool_call_correctness_rate', \n",
    "                         'tool_call_success_rate',\n",
    "                         'context_retention_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metric_name': 'goal_decomposition_efficiency',\n",
       "  'score': 0.85,\n",
       "  'reason': \"The AI effectively decomposed the original goal into clear and relevant sub-tasks that align well with the user's objectives. Each sub-task is logically sequenced, allowing for a structured approach to achieving the overall goal. The tools used correspond appropriately to the sub-tasks, and the decomposition covers all necessary aspects of the investment decision-making process. However, there could be slight improvements in granularity, particularly in the analysis of market conditions, which could benefit from more detailed insights. Overall, the decomposition is efficient and facilitates a comprehensive approach to the user's investment strategy.\",\n",
       "  'result_detail': {'metric_name': 'goal_fulfillment_rate',\n",
       "   'config': {},\n",
       "   'result': {'originalGoal': 'Make informed investment decisions regarding Apple Inc. (AAPL) stock by analyzing current stock data, news sentiment, and economic indicators, and executing a buy order.',\n",
       "    'subtasks': ['Fetch current stock data for AAPL.',\n",
       "     'Retrieve recent news articles related to AAPL.',\n",
       "     'Analyze sentiment for each news article.',\n",
       "     'Gather relevant economic indicators.',\n",
       "     'Analyze market conditions based on stock data, news sentiment, and economic indicators.',\n",
       "     'Generate an investment recommendation based on the market outlook and investor risk tolerance.',\n",
       "     'Execute a buy order for AAPL.'],\n",
       "    'score': 0.85,\n",
       "    'reason': \"The AI effectively decomposed the original goal into clear and relevant sub-tasks that align well with the user's objectives. Each sub-task is logically sequenced, allowing for a structured approach to achieving the overall goal. The tools used correspond appropriately to the sub-tasks, and the decomposition covers all necessary aspects of the investment decision-making process. However, there could be slight improvements in granularity, particularly in the analysis of market conditions, which could benefit from more detailed insights. Overall, the decomposition is efficient and facilitates a comprehensive approach to the user's investment strategy.\"}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T12:36:44.319561',\n",
       "  'end_time': '2024-11-19T12:36:54.867682',\n",
       "  'duration': 10.548121},\n",
       " {'metric_name': 'goal_fulfillment_rate',\n",
       "  'score': 0.75,\n",
       "  'reason': \"The system responses effectively address the user's intent to make informed investment decisions regarding Apple Inc. (AAPL) stock. The responses include fetching current stock data, relevant news articles, sentiment analysis, and economic indicators, which are crucial for the user's analysis. The stock data indicates a slight decline in price, which aligns with the user's concern about recent performance. The news articles provide context, although the sentiment analysis scores are low, indicating mixed or slightly positive sentiment, which may not fully satisfy the user's need for comprehensive sentiment evaluation. The economic indicators are relevant and provide additional context for market conditions. The investment recommendation is well-aligned with the user's moderate risk tolerance and suggests a balanced approach, which is appropriate given the user's intent. However, the lack of an executed buy order indicates that the final step of the user's goal is not fulfilled, which slightly lowers the overall score. Overall, the system responses are informative and relevant, but the incomplete execution of the buy order prevents a perfect score.\",\n",
       "  'result_detail': {'metric_name': 'goal_fulfillment_rate',\n",
       "   'config': {},\n",
       "   'result': {'inputGoal': \"The user aims to make informed investment decisions regarding Apple Inc. (AAPL) stock. They seek to analyze current stock data, news sentiment, and economic indicators to understand the market conditions better. After evaluating the information, the user intends to execute a buy order for AAPL, indicating a belief in its long-term growth potential despite a recent decline in stock price. Overall, the user's goal is to strategically invest in AAPL while considering their moderate risk tolerance.\",\n",
       "    'relevantResponses': \"fetch_stock_data: {'symbol': 'AAPL', 'price': 353.24, 'change': -1.08}\\n\\nfetch_news_articles: ['AAPL announces new product line', 'AAPL reports quarterly earnings', 'AAPL faces regulatory scrutiny']\\n\\nanalyze_sentiment: 0.13636363636363635\\n\\nanalyze_sentiment: 0.0\\n\\nanalyze_sentiment: 0.0\\n\\nfetch_economic_indicators: {'gdp_growth': 1.18, 'unemployment_rate': 5.0, 'inflation_rate': 1.14}\\n\\nanalyze_market_conditions: Based on the provided data, we can create a concise market outlook focusing on the stock in question, Apple Inc. (AAPL), in the context of the prevailing economic indicators and sentiment analysis.\\n\\n### Stock Analysis: Apple Inc. (AAPL)\\n- **Current Stock Price:** $353.24\\n- **Percentage Change:** -1.08%\\n\\nThis decline in Apple’s stock price points to a negative market reaction on the trading day in question. However, this should be contextualized within broader market trends, the company's performance, and specific news events impacting the stock.\\n\\n### News Sentiment: 0.04545454545454545\\nThe news sentiment score, marginally above zero, suggests a slightly positive bias in news coverage concerning\\n\\ngenerate_investment_recommendation: Given the provided market outlook for Apple Inc. (AAPL), which highlights a recent decline in stock price and a slightly positive news sentiment, coupled with your moderate risk tolerance, a specific investment recommendation would entail a balanced approach that combines growth with a degree of caution. Here's the strategy:\\n\\n### Recommended Investment Strategy: Buy and Hold with Monitoring\\n\\n1. **Initial Purchase**: Considering the slight positive bias in news sentiment and your moderate risk tolerance, initiating a modest position in AAPL could be a prudent move. The recent dip in stock price may present a buying opportunity, assuming you believe in the company's long-term growth prospects. Apple, as a leading technology company, has shown resilience and innovation over the years, which could translate to stock recovery and growth over time.\\n\\n2. **Diversification**: To mitigate the risks associated with investing in a single stock and to balance your investment portfolio, consider diversifying across different sectors and asset classes. This may include bonds, ETFs, and stocks in\\n\\nexecute_buy_order: None\",\n",
       "    'score': 0.75,\n",
       "    'reason': \"The system responses effectively address the user's intent to make informed investment decisions regarding Apple Inc. (AAPL) stock. The responses include fetching current stock data, relevant news articles, sentiment analysis, and economic indicators, which are crucial for the user's analysis. The stock data indicates a slight decline in price, which aligns with the user's concern about recent performance. The news articles provide context, although the sentiment analysis scores are low, indicating mixed or slightly positive sentiment, which may not fully satisfy the user's need for comprehensive sentiment evaluation. The economic indicators are relevant and provide additional context for market conditions. The investment recommendation is well-aligned with the user's moderate risk tolerance and suggests a balanced approach, which is appropriate given the user's intent. However, the lack of an executed buy order indicates that the final step of the user's goal is not fulfilled, which slightly lowers the overall score. Overall, the system responses are informative and relevant, but the incomplete execution of the buy order prevents a perfect score.\"}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T12:36:54.867682',\n",
       "  'end_time': '2024-11-19T12:37:03.324747',\n",
       "  'duration': 8.457065},\n",
       " {'metric_name': 'tool_call_correctness_rate',\n",
       "  'score': 0.42857142857142855,\n",
       "  'reason': \"The correctness rate of 0.43 (or 43%) in this interaction can be explained by analyzing the tool usage against the intended tools and the actual calls made.\\n\\n1. **Intended Tools**: The intended tools for the query were:\\n   - `fetch_news_articles`: To gather relevant news articles that could impact the stock's performance.\\n   - `fetch_economic_indicators`: To obtain current economic data that influences market conditions.\\n   - `fetch_stock_data`: To retrieve the latest stock information for AAPL.\\n\\n2. **Actual Tool Usage**: The actual calls made were 7, but only 3 of them were correct, meaning they aligned with the intended tools. The remaining 4 calls likely included tools that were not necessary for the analysis, such as `analyze_sentiment` and `execute_buy_order`, which do not directly contribute to providing a market outlook based on the given data.\\n\\n3. **Analysis of Correctness Rate**: The correctness rate is calculated as the number of correct calls divided by the total calls made:\\n   \\\\[\\n   \\\\text{Correctness Rate} = \\\\frac{\\\\text{Correct Calls}}{\\\\text{Total Calls}} = \\\\frac{3}{7} \\\\approx 0.43\\n   \\\\]\\n   This indicates that while some relevant tools were used correctly, a significant number of unnecessary or incorrect tools were also called, leading to a lower overall correctness rate.\\n\\nIn summary, the correctness rate reflects the effectiveness of tool selection in relation to the query's requirements. The presence of unnecessary tool calls diluted the effectiveness of the correct calls, resulting in a lower correctness rate.\",\n",
       "  'result_detail': {'metric_name': 'tool_correctness',\n",
       "   'config': {},\n",
       "   'result': {'score': 0.42857142857142855,\n",
       "    'reason': \"The correctness rate of 0.43 (or 43%) in this interaction can be explained by analyzing the tool usage against the intended tools and the actual calls made.\\n\\n1. **Intended Tools**: The intended tools for the query were:\\n   - `fetch_news_articles`: To gather relevant news articles that could impact the stock's performance.\\n   - `fetch_economic_indicators`: To obtain current economic data that influences market conditions.\\n   - `fetch_stock_data`: To retrieve the latest stock information for AAPL.\\n\\n2. **Actual Tool Usage**: The actual calls made were 7, but only 3 of them were correct, meaning they aligned with the intended tools. The remaining 4 calls likely included tools that were not necessary for the analysis, such as `analyze_sentiment` and `execute_buy_order`, which do not directly contribute to providing a market outlook based on the given data.\\n\\n3. **Analysis of Correctness Rate**: The correctness rate is calculated as the number of correct calls divided by the total calls made:\\n   \\\\[\\n   \\\\text{Correctness Rate} = \\\\frac{\\\\text{Correct Calls}}{\\\\text{Total Calls}} = \\\\frac{3}{7} \\\\approx 0.43\\n   \\\\]\\n   This indicates that while some relevant tools were used correctly, a significant number of unnecessary or incorrect tools were also called, leading to a lower overall correctness rate.\\n\\nIn summary, the correctness rate reflects the effectiveness of tool selection in relation to the query's requirements. The presence of unnecessary tool calls diluted the effectiveness of the correct calls, resulting in a lower correctness rate.\",\n",
       "    'details': {'correct_calls': 3,\n",
       "     'total_calls': 7,\n",
       "     'intended_tools': ['fetch_news_articles',\n",
       "      'fetch_economic_indicators',\n",
       "      'fetch_stock_data'],\n",
       "     'available_tools': ['fetch_news_articles',\n",
       "      'analyze_sentiment',\n",
       "      'fetch_stock_data',\n",
       "      'execute_buy_order',\n",
       "      'fetch_economic_indicators']}}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T12:37:03.324747',\n",
       "  'end_time': '2024-11-19T12:37:09.816785',\n",
       "  'duration': 6.492038},\n",
       " {'metric_name': 'tool_call_success_rate',\n",
       "  'score': 0.8571428571428571,\n",
       "  'reason': 'The overall performance of the tool call was successful, with a high success rate of 0.86. Most of the tool call results indicated successful execution, with valid outputs and expected information being returned. However, there was one instance where the tool call output was None, indicating a potential error during execution. This highlights the need for further investigation and potential improvement in error handling to ensure consistent successful outcomes.',\n",
       "  'result_detail': {'metric_name': 'tool_call_success_rate',\n",
       "   'config': {},\n",
       "   'result': {'score': 0.8571428571428571,\n",
       "    'reason': 'The overall performance of the tool call was successful, with a high success rate of 0.86. Most of the tool call results indicated successful execution, with valid outputs and expected information being returned. However, there was one instance where the tool call output was None, indicating a potential error during execution. This highlights the need for further investigation and potential improvement in error handling to ensure consistent successful outcomes.'}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T12:37:09.816785',\n",
       "  'end_time': '2024-11-19T12:37:19.802576',\n",
       "  'duration': 9.985791},\n",
       " {'metric_name': 'context_retention_rate',\n",
       "  'score': 0.24,\n",
       "  'reason': 'The conversation demonstrates some coherence in terms of maintaining relevant information about the stock AAPL and its associated news articles. However, there are significant issues with context retention and information reuse. The context switches are frequent, leading to a fragmented flow of information, and the context maintenance score is notably low, indicating that the system struggles to retain and utilize previously mentioned information effectively. Additionally, while the referenced information is relevant, it is not consistently applied across interactions, leading to a lack of clarity in the final investment recommendation. Overall, the conversation lacks the necessary coherence and effectiveness in context retention to achieve a higher score.',\n",
       "  'result_detail': {'metric_name': 'context_retention_rate',\n",
       "   'config': {},\n",
       "   'result': {'score': 0.24,\n",
       "    'reason': 'The conversation demonstrates some coherence in terms of maintaining relevant information about the stock AAPL and its associated news articles. However, there are significant issues with context retention and information reuse. The context switches are frequent, leading to a fragmented flow of information, and the context maintenance score is notably low, indicating that the system struggles to retain and utilize previously mentioned information effectively. Additionally, while the referenced information is relevant, it is not consistently applied across interactions, leading to a lack of clarity in the final investment recommendation. Overall, the conversation lacks the necessary coherence and effectiveness in context retention to achieve a higher score.',\n",
       "    'context_metrics': {'context_switches': 8,\n",
       "     'context_maintenance_score': 0.0,\n",
       "     'total_key_points': 33},\n",
       "    'coherence_analysis': {'coherence_score': 0.4,\n",
       "     'key_observations': [\"The conversation maintains relevant information about AAPL's stock price and news articles, but struggles with context retention.\",\n",
       "      'Frequent context switches disrupt the flow of the conversation, making it harder to follow.',\n",
       "      'The context maintenance score is 0.0, indicating poor retention of previously mentioned information.',\n",
       "      'Information reuse is consistently low, suggesting that the system does not effectively leverage past interactions.',\n",
       "      'The final investment recommendation lacks clarity due to inconsistent application of referenced information.']},\n",
       "    'execution_stats': {'total_interactions': 9, 'average_info_reuse': 0.0}}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T12:37:19.802576',\n",
       "  'end_time': '2024-11-19T12:37:47.898536',\n",
       "  'duration': 28.09596}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = exe.get_results()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Results\n",
    "\n",
    "After running the analysis, you can examine the output to see the stock data, news sentiment, economic indicators, and the investment recommendation. The AgentNeo tracer will have logged all the steps of the process, which you can later analyze using the AgentNeo dashboard.\n",
    "\n",
    "To launch the AgentNeo dashboard and analyze the traces, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dashboard process started successfully\n",
      "INFO:root:Dashboard launched successfully. Access it at: http://localhost:3000\n"
     ]
    }
   ],
   "source": [
    "neo_session.launch_dashboard(port=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow you to visualize the execution flow, identify any bottlenecks, and gain insights into the decision-making process of your financial analysis system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
