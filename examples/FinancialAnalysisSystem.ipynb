{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Analysis System with AgentNeo Integration\n",
    "\n",
    "This Jupyter notebook demonstrates the integration of AgentNeo, a powerful tracing and monitoring tool, with a financial analysis system. AgentNeo provides seamless tracing capabilities for both function calls and AI model interactions, allowing for comprehensive analysis and debugging of complex systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from agentneo import AgentNeo, Tracer, Evaluation\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"YOUR_ENV_FILE\")\n",
    "\n",
    "# Initialize OpenAI API\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinancialAnalysisSystem Class\n",
    "\n",
    "Now, let's define our `FinancialAnalysisSystem` class with AgentNeo integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project connected successfully\n",
      "Project 'financial_analysis_project2' found.\n",
      "Tracing Started.\n"
     ]
    }
   ],
   "source": [
    "# Initialize AgentNeo session\n",
    "neo_session = AgentNeo(session_name=\"financial_analysis_session2\")\n",
    "\n",
    "project_name = \"financial_analysis_project2\"\n",
    "# Create project\n",
    "try:\n",
    "    neo_session.create_project(project_name=project_name)\n",
    "    print(\"Project created successfully\")\n",
    "# Connect project\n",
    "except:\n",
    "    neo_session.connect_project(project_name=project_name)\n",
    "    print(\"Project connected successfully\")\n",
    "\n",
    "# Start tracing\n",
    "tracer = Tracer(session=neo_session)\n",
    "tracer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialAnalysisSystem:\n",
    "    def __init__(self):\n",
    "        self.stock_data = {}\n",
    "        self.news_sentiment = {}\n",
    "        self.economic_indicators = {}\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_stock_data\")\n",
    "    def fetch_stock_data(self, symbol):\n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"price\": round(random.uniform(50, 500), 2),\n",
    "            \"change\": round(random.uniform(-5, 5), 2),\n",
    "        }\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_news_articles\")\n",
    "    def fetch_news_articles(self, company):\n",
    "        return [\n",
    "            f\"{company} announces new product line\",\n",
    "            f\"{company} reports quarterly earnings\",\n",
    "            f\"{company} faces regulatory scrutiny\",\n",
    "        ]\n",
    "\n",
    "    @tracer.trace_tool(name=\"analyze_sentiment\")\n",
    "    def analyze_sentiment(self, text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_economic_indicators\")\n",
    "    def fetch_economic_indicators(self):\n",
    "        return {\n",
    "            \"gdp_growth\": round(random.uniform(-2, 5), 2),\n",
    "            \"unemployment_rate\": round(random.uniform(3, 10), 2),\n",
    "            \"inflation_rate\": round(random.uniform(0, 5), 2),\n",
    "        }\n",
    "\n",
    "    @tracer.trace_llm(name=\"analyze_market_conditions\")\n",
    "    def analyze_market_conditions(self, stock_data, sentiment, economic_indicators):\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following market conditions and provide a brief market outlook:\n",
    "        Stock: {stock_data['symbol']} at ${stock_data['price']} (change: {stock_data['change']}%)\n",
    "        News Sentiment: {sentiment}\n",
    "        Economic Indicators:\n",
    "        - GDP Growth: {economic_indicators['gdp_growth']}%\n",
    "        - Unemployment Rate: {economic_indicators['unemployment_rate']}%\n",
    "        - Inflation Rate: {economic_indicators['inflation_rate']}%\n",
    "        \"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    @tracer.trace_llm(name=\"generate_investment_recommendation\")\n",
    "    def generate_investment_recommendation(self, market_outlook, risk_tolerance):\n",
    "        prompt = f\"\"\"\n",
    "        Based on the following market outlook and investor risk tolerance,\n",
    "        provide a specific investment recommendation:\n",
    "        Market Outlook: {market_outlook}\n",
    "        Investor Risk Tolerance: {risk_tolerance}\n",
    "        \"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    @tracer.trace_agent(name=\"FinancialAdvisorAgent\")\n",
    "    def financial_advisor_agent(self, stock_symbol, risk_tolerance):\n",
    "        self.stock_data = self.fetch_stock_data(stock_symbol)\n",
    "        news_articles = self.fetch_news_articles(stock_symbol)\n",
    "        sentiment_scores = [self.analyze_sentiment(article) for article in news_articles]\n",
    "        self.news_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        self.economic_indicators = self.fetch_economic_indicators()\n",
    "        market_outlook = self.analyze_market_conditions(\n",
    "            self.stock_data, self.news_sentiment, self.economic_indicators\n",
    "        )\n",
    "        recommendation = self.generate_investment_recommendation(market_outlook, risk_tolerance)\n",
    "        return recommendation\n",
    "\n",
    "    def run_analysis(self, stock_symbol, risk_tolerance):\n",
    "        recommendation = self.financial_advisor_agent(stock_symbol, risk_tolerance)\n",
    "        print(f\"\\nAnalysis for {stock_symbol}:\")\n",
    "        print(f\"Stock Data: {self.stock_data}\")\n",
    "        print(f\"News Sentiment: {self.news_sentiment}\")\n",
    "        print(f\"Economic Indicators: {self.economic_indicators}\")\n",
    "        print(f\"\\nInvestment Recommendation:\\n{recommendation}\")\n",
    "        if \"buy\" in recommendation.lower():\n",
    "            self.execute_buy_order(stock_symbol)\n",
    "        elif \"sell\" in recommendation.lower():\n",
    "            self.execute_sell_order(stock_symbol)\n",
    "        else:\n",
    "            print(\"No action taken based on the current recommendation.\")\n",
    "\n",
    "    @tracer.trace_tool(name=\"execute_buy_order\")\n",
    "    def execute_buy_order(self, symbol):\n",
    "        print(f\"Executing buy order for {symbol}\")\n",
    "\n",
    "    @tracer.trace_tool(name=\"execute_sell_order\")\n",
    "    def execute_sell_order(self, symbol):\n",
    "        print(f\"Executing sell order for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Analysis\n",
    "\n",
    "Now let's create an instance of our `FinancialAnalysisSystem` and run an analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:agentneo.tracing.agent_tracer:Successfully updated and committed AgentCallModel with id 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for AAPL:\n",
      "Stock Data: {'symbol': 'AAPL', 'price': 170.99, 'change': -4.44}\n",
      "News Sentiment: 0.04545454545454545\n",
      "Economic Indicators: {'gdp_growth': -0.86, 'unemployment_rate': 8.18, 'inflation_rate': 2.61}\n",
      "\n",
      "Investment Recommendation:\n",
      "Given the market outlook and the investor's moderate risk tolerance, a specific investment recommendation would involve a balanced approach that accounts for the potential rewards associated with Apple Inc. (AAPL) while also mitigating risks through diversification and careful selection of securities. Here's the recommendation:\n",
      "\n",
      "**Diversified Investment Strategy with a Focus on Apple Inc. (AAPL):**\n",
      "\n",
      "1. **AAPL Position Sizing:** Given AAPL's current trading situation, with a slight decline and a relatively low yet positive news sentiment, it may be advisable to include AAPL in the investment portfolio but with limited exposure. Consider allocating a portion of the portfolio to AAPL that reflects the investor's moderate risk tolerance, such as 10-15%. This size allows the investor to potentially benefit from AAPL's growth and recovery without significantly exposing the portfolio to the stock's volatility.\n",
      "\n",
      "2. **Sector Diversification:** To reduce the impact of sector-specific risks, particularly from the tech sector that AAPL is a part\n",
      "No action taken based on the current recommendation.\n",
      "Tracing Completed.\n",
      "Data saved to the database and JSON file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of FinancialAnalysisSystem\n",
    "analysis_system = FinancialAnalysisSystem()\n",
    "\n",
    "# Run an analysis for Apple stock with moderate risk tolerance\n",
    "analysis_system.run_analysis(\"AAPL\", \"moderate\")\n",
    "\n",
    "# Stop the tracer when analysis is complete\n",
    "tracer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m17:49:13 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:15 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:15 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:17 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:17 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:20 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:20 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:22 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:22 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:29 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:29 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting query: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:30 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:30 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:31 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:31 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:32 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:32 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:33 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:33 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:34 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:34 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:35 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m17:49:35 - LiteLLM:INFO\u001b[0m: utils.py:2687 - \n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-3.5-turbo; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m17:49:36 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "exe = Evaluation(session=neo_session, trace_id=tracer.trace_id)\n",
    "\n",
    "# run a single metric\n",
    "exe.evaluate(metric_list=['goal_decomposition_efficiency', \n",
    "                         'goal_fulfillment_rate', \n",
    "                         'tool_call_correctness_rate', \n",
    "                         'tool_call_success_rate',\n",
    "                         'response_latency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metric_name': 'goal_decomposition_efficiency',\n",
       "  'score': 0.85,\n",
       "  'reason': \"The AI effectively decomposed the original goal into clear and relevant sub-tasks that align well with the user's intent. Each sub-task is appropriately assigned to the corresponding tool, and all aspects of the original goal are covered. The logical sequence of tasks allows for efficient execution, and the independence of sub-tasks facilitates parallel processing. However, the sentiment analysis could be more granular by providing a summary of overall sentiment rather than individual scores, which slightly affects completeness.\",\n",
       "  'result_detail': {'metric_name': 'goal_fulfillment_rate',\n",
       "   'config': {},\n",
       "   'result': {'originalGoal': 'Gather comprehensive information about Apple Inc. (AAPL) to inform investment decisions, including current stock price, recent news articles, sentiment analysis, and relevant economic indicators.',\n",
       "    'subtasks': ['Fetch current stock price for AAPL.',\n",
       "     'Retrieve recent news articles related to AAPL.',\n",
       "     'Analyze sentiment for each news article.',\n",
       "     'Fetch relevant economic indicators.'],\n",
       "    'score': 0.85,\n",
       "    'reason': \"The AI effectively decomposed the original goal into clear and relevant sub-tasks that align well with the user's intent. Each sub-task is appropriately assigned to the corresponding tool, and all aspects of the original goal are covered. The logical sequence of tasks allows for efficient execution, and the independence of sub-tasks facilitates parallel processing. However, the sentiment analysis could be more granular by providing a summary of overall sentiment rather than individual scores, which slightly affects completeness.\"}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T17:49:13.262330',\n",
       "  'end_time': '2024-11-19T17:49:20.642423',\n",
       "  'duration': 7.380093},\n",
       " {'metric_name': 'goal_fulfillment_rate',\n",
       "  'score': 0.7,\n",
       "  'reason': \"The system responses partially fulfill the user's intent to gather comprehensive information about Apple Inc. (AAPL) for investment decisions. The user is looking for real-time stock data, news articles, sentiment analysis, and broader economic indicators. The system successfully provides real-time stock data with the current price and change, which is essential for investment decisions. It also fetches relevant news articles that can inform the user about AAPL's recent activities and performance. However, the sentiment analysis results are concerning; while one article has a positive sentiment score (0.136), the other two articles have a score of 0.0, indicating a lack of positive sentiment in the news, which may not provide a balanced view of market perception. Additionally, the economic indicators provided (GDP growth, unemployment rate, inflation rate) are relevant and necessary for understanding the broader economic context affecting AAPL's performance. Overall, while the system provides key information, the sentiment analysis lacks depth and balance, which slightly diminishes the overall fulfillment of the user's intent.\",\n",
       "  'result_detail': {'metric_name': 'goal_fulfillment_rate',\n",
       "   'config': {},\n",
       "   'result': {'inputGoal': \"The user is focused on gathering comprehensive information about Apple Inc. (AAPL) to inform their investment decisions. They are seeking real-time stock data, news articles related to AAPL, and sentiment analysis of those news articles to gauge market perception. Additionally, the user is interested in understanding broader economic indicators that may impact AAPL's performance. Overall, their intent is to analyze AAPL's current market position and potential future movements based on various data points.\",\n",
       "    'relevantResponses': \"fetch_stock_data: {'symbol': 'AAPL', 'price': 170.99, 'change': -4.44}\\n\\nfetch_news_articles: ['AAPL announces new product line', 'AAPL reports quarterly earnings', 'AAPL faces regulatory scrutiny']\\n\\nanalyze_sentiment: 0.13636363636363635\\n\\nanalyze_sentiment: 0.0\\n\\nanalyze_sentiment: 0.0\\n\\nfetch_economic_indicators: {'gdp_growth': -0.86, 'unemployment_rate': 8.18, 'inflation_rate': 2.61}\",\n",
       "    'score': 0.7,\n",
       "    'reason': \"The system responses partially fulfill the user's intent to gather comprehensive information about Apple Inc. (AAPL) for investment decisions. The user is looking for real-time stock data, news articles, sentiment analysis, and broader economic indicators. The system successfully provides real-time stock data with the current price and change, which is essential for investment decisions. It also fetches relevant news articles that can inform the user about AAPL's recent activities and performance. However, the sentiment analysis results are concerning; while one article has a positive sentiment score (0.136), the other two articles have a score of 0.0, indicating a lack of positive sentiment in the news, which may not provide a balanced view of market perception. Additionally, the economic indicators provided (GDP growth, unemployment rate, inflation rate) are relevant and necessary for understanding the broader economic context affecting AAPL's performance. Overall, while the system provides key information, the sentiment analysis lacks depth and balance, which slightly diminishes the overall fulfillment of the user's intent.\"}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T17:49:20.642423',\n",
       "  'end_time': '2024-11-19T17:49:29.246331',\n",
       "  'duration': 8.603908},\n",
       " {'metric_name': 'tool_call_correctness_rate',\n",
       "  'score': 0.0,\n",
       "  'reason': 'Unable to extract query from trace_json: list index out of range',\n",
       "  'result_detail': {'metric_name': 'tool_correctness',\n",
       "   'config': {},\n",
       "   'result': {'score': 0,\n",
       "    'reason': 'Unable to extract query from trace_json: list index out of range'}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T17:49:29.246331',\n",
       "  'end_time': '2024-11-19T17:49:29.246331',\n",
       "  'duration': 0.0},\n",
       " {'metric_name': 'tool_call_success_rate',\n",
       "  'score': 1.0,\n",
       "  'reason': 'The tool call performance was exceptional, with a 100% success rate across all evaluations. The tool successfully retrieved and processed data related to AAPL, numerical values, and economic indicators without any apparent errors. The tool consistently provided the expected output, indicating efficient and accurate functionality.',\n",
       "  'result_detail': {'metric_name': 'tool_call_success_rate',\n",
       "   'config': {},\n",
       "   'result': {'score': 1.0,\n",
       "    'reason': 'The tool call performance was exceptional, with a 100% success rate across all evaluations. The tool successfully retrieved and processed data related to AAPL, numerical values, and economic indicators without any apparent errors. The tool consistently provided the expected output, indicating efficient and accurate functionality.'}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T17:49:29.246331',\n",
       "  'end_time': '2024-11-19T17:49:36.824815',\n",
       "  'duration': 7.578484},\n",
       " {'metric_name': 'response_latency',\n",
       "  'score': 0.0007509999999999999,\n",
       "  'reason': 'Response latency metrics successfully calculated.',\n",
       "  'result_detail': {'metric_name': 'response_latency',\n",
       "   'config': {},\n",
       "   'result': {'score': 0.0007509999999999999,\n",
       "    'reason': 'Response latency metrics successfully calculated.',\n",
       "    'details': {'average_latency': 0.0007509999999999999,\n",
       "     'min_latency': 0.0,\n",
       "     'max_latency': 0.004506,\n",
       "     'median_latency': 0.0,\n",
       "     'p90_latency': 0.004506,\n",
       "     'std_dev_latency': 0.0016792870511023418}}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-11-19T17:49:36.824815',\n",
       "  'end_time': '2024-11-19T17:49:36.824815',\n",
       "  'duration': 0.0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = exe.get_results()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Results\n",
    "\n",
    "After running the analysis, you can examine the output to see the stock data, news sentiment, economic indicators, and the investment recommendation. The AgentNeo tracer will have logged all the steps of the process, which you can later analyze using the AgentNeo dashboard.\n",
    "\n",
    "To launch the AgentNeo dashboard and analyze the traces, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dashboard process started successfully\n",
      "INFO:root:Dashboard launched successfully. Access it at: http://localhost:3000\n"
     ]
    }
   ],
   "source": [
    "neo_session.launch_dashboard(port=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow you to visualize the execution flow, identify any bottlenecks, and gain insights into the decision-making process of your financial analysis system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
