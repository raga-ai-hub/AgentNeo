{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Analysis System with AgentNeo Integration\n",
    "\n",
    "This Jupyter notebook demonstrates the integration of AgentNeo, a powerful tracing and monitoring tool, with a financial analysis system. AgentNeo provides seamless tracing capabilities for both function calls and AI model interactions, allowing for comprehensive analysis and debugging of complex systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from agentneo import AgentNeo, Tracer, Evaluation\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"YOUR_ENV_FILE\")\n",
    "\n",
    "# Initialize OpenAI API\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinancialAnalysisSystem Class\n",
    "\n",
    "Now, let's define our `FinancialAnalysisSystem` class with AgentNeo integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project 'financial_analysis_project22' found.\n",
      "Tracing Started.\n"
     ]
    }
   ],
   "source": [
    "# Initialize AgentNeo session\n",
    "neo_session = AgentNeo(session_name=\"financial_analysis_session22\")\n",
    "\n",
    "# Create project\n",
    "neo_session.create_project(project_name=\"financial_analysis_project22\")\n",
    "\n",
    "# Start tracing\n",
    "tracer = Tracer(session=neo_session)\n",
    "tracer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialAnalysisSystem:\n",
    "    def __init__(self):\n",
    "        self.stock_data = {}\n",
    "        self.news_sentiment = {}\n",
    "        self.economic_indicators = {}\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_stock_data\")\n",
    "    def fetch_stock_data(self, symbol):\n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"price\": round(random.uniform(50, 500), 2),\n",
    "            \"change\": round(random.uniform(-5, 5), 2),\n",
    "        }\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_news_articles\")\n",
    "    def fetch_news_articles(self, company):\n",
    "        return [\n",
    "            f\"{company} announces new product line\",\n",
    "            f\"{company} reports quarterly earnings\",\n",
    "            f\"{company} faces regulatory scrutiny\",\n",
    "        ]\n",
    "\n",
    "    @tracer.trace_tool(name=\"analyze_sentiment\")\n",
    "    def analyze_sentiment(self, text):\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "\n",
    "    @tracer.trace_tool(name=\"fetch_economic_indicators\")\n",
    "    def fetch_economic_indicators(self):\n",
    "        return {\n",
    "            \"gdp_growth\": round(random.uniform(-2, 5), 2),\n",
    "            \"unemployment_rate\": round(random.uniform(3, 10), 2),\n",
    "            \"inflation_rate\": round(random.uniform(0, 5), 2),\n",
    "        }\n",
    "\n",
    "    @tracer.trace_llm(name=\"analyze_market_conditions\")\n",
    "    def analyze_market_conditions(self, stock_data, sentiment, economic_indicators):\n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following market conditions and provide a brief market outlook:\n",
    "        Stock: {stock_data['symbol']} at ${stock_data['price']} (change: {stock_data['change']}%)\n",
    "        News Sentiment: {sentiment}\n",
    "        Economic Indicators:\n",
    "        - GDP Growth: {economic_indicators['gdp_growth']}%\n",
    "        - Unemployment Rate: {economic_indicators['unemployment_rate']}%\n",
    "        - Inflation Rate: {economic_indicators['inflation_rate']}%\n",
    "        \"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    @tracer.trace_llm(name=\"generate_investment_recommendation\")\n",
    "    def generate_investment_recommendation(self, market_outlook, risk_tolerance):\n",
    "        prompt = f\"\"\"\n",
    "        Based on the following market outlook and investor risk tolerance,\n",
    "        provide a specific investment recommendation:\n",
    "        Market Outlook: {market_outlook}\n",
    "        Investor Risk Tolerance: {risk_tolerance}\n",
    "        \"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    @tracer.trace_agent(name=\"FinancialAdvisorAgent\")\n",
    "    def financial_advisor_agent(self, stock_symbol, risk_tolerance):\n",
    "        self.stock_data = self.fetch_stock_data(stock_symbol)\n",
    "        news_articles = self.fetch_news_articles(stock_symbol)\n",
    "        sentiment_scores = [self.analyze_sentiment(article) for article in news_articles]\n",
    "        self.news_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
    "        self.economic_indicators = self.fetch_economic_indicators()\n",
    "        market_outlook = self.analyze_market_conditions(\n",
    "            self.stock_data, self.news_sentiment, self.economic_indicators\n",
    "        )\n",
    "        recommendation = self.generate_investment_recommendation(market_outlook, risk_tolerance)\n",
    "        return recommendation\n",
    "\n",
    "    def run_analysis(self, stock_symbol, risk_tolerance):\n",
    "        recommendation = self.financial_advisor_agent(stock_symbol, risk_tolerance)\n",
    "        print(f\"\\nAnalysis for {stock_symbol}:\")\n",
    "        print(f\"Stock Data: {self.stock_data}\")\n",
    "        print(f\"News Sentiment: {self.news_sentiment}\")\n",
    "        print(f\"Economic Indicators: {self.economic_indicators}\")\n",
    "        print(f\"\\nInvestment Recommendation:\\n{recommendation}\")\n",
    "        if \"buy\" in recommendation.lower():\n",
    "            self.execute_buy_order(stock_symbol)\n",
    "        elif \"sell\" in recommendation.lower():\n",
    "            self.execute_sell_order(stock_symbol)\n",
    "        else:\n",
    "            print(\"No action taken based on the current recommendation.\")\n",
    "\n",
    "    @tracer.trace_tool(name=\"execute_buy_order\")\n",
    "    def execute_buy_order(self, symbol):\n",
    "        print(f\"Executing buy order for {symbol}\")\n",
    "\n",
    "    @tracer.trace_tool(name=\"execute_sell_order\")\n",
    "    def execute_sell_order(self, symbol):\n",
    "        print(f\"Executing sell order for {symbol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Analysis\n",
    "\n",
    "Now let's create an instance of our `FinancialAnalysisSystem` and run an analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:agentneo.tracing.agent_tracer:Successfully updated and committed AgentCallModel with id 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for AAPL:\n",
      "Stock Data: {'symbol': 'AAPL', 'price': 393.39, 'change': -4.34}\n",
      "News Sentiment: 0.04545454545454545\n",
      "Economic Indicators: {'gdp_growth': 4.48, 'unemployment_rate': 6.6, 'inflation_rate': 3.55}\n",
      "\n",
      "Investment Recommendation:\n",
      "Given the market outlook and the moderate risk tolerance of the investor, the recommended course of action would be to adopt a cautious yet opportunistic approach towards investing in Apple Inc. (AAPL). Here's a tailored investment strategy encompassing both the short-term market outlook and the investor's risk preference:\n",
      "\n",
      "### 1. Hold and Monitor:\n",
      "- **For Existing Investors**: If the investor already holds AAPL in their portfolio, the advice would be to hold onto the shares for now but to monitor the stock closely. Given the short-term negative movement, it is essential to keep an eye on upcoming earnings reports, news releases, and broader market conditions that could further impact the stock's performance. Setting a stop-loss limit might also be prudent to prevent significant losses if the stock's price continues to fall.\n",
      "\n",
      "### 2. Dollar-Cost Averaging (DCA):\n",
      "- **For Potential Investors**: For those considering adding AAPL to their portfolio, employing a dollar-cost averaging strategy could be advantageous, especially\n",
      "No action taken based on the current recommendation.\n",
      "Tracing Completed.\n",
      "Data saved to the database and JSON file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of FinancialAnalysisSystem\n",
    "analysis_system = FinancialAnalysisSystem()\n",
    "\n",
    "# Run an analysis for Apple stock with moderate risk tolerance\n",
    "analysis_system.run_analysis(\"AAPL\", \"moderate\")\n",
    "\n",
    "# Stop the tracer when analysis is complete\n",
    "tracer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:20:55 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:20:57 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:20:57 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:20:58 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:20:58 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:21:02 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:21:02 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:21:04 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:21:04 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:21:05 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:21:05 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:21:09 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:21:09 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:21:10 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:21:10 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:21:11 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "exe = Evaluation(session=neo_session, trace_id=tracer.trace_id)\n",
    "\n",
    "# run a single metric\n",
    "exe.evaluate(metric_list=['goal_decomposition_efficiency', \n",
    "                         'goal_decomposition_efficiency', \n",
    "                         'tool_correctness_metric', \n",
    "                         'tool_correctness_metric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Results\n",
    "\n",
    "After running the analysis, you can examine the output to see the stock data, news sentiment, economic indicators, and the investment recommendation. The AgentNeo tracer will have logged all the steps of the process, which you can later analyze using the AgentNeo dashboard.\n",
    "\n",
    "To launch the AgentNeo dashboard and analyze the traces, you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_session.launch_dashboard(port=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow you to visualize the execution flow, identify any bottlenecks, and gain insights into the decision-making process of your financial analysis system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
