{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Langgraph with AgentNeo Integration\n",
    " This Jupyter notebook demonstrates the integration of AgentNeo, a powerful tracing and monitoring tool, with Langgraph, a graph-based approach to managing language models with an agent-based system to enhance the automation and decision-making capabilities of your application. This integration allows for comprehensive analysis and debugging of AI-powered systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Setup and Imports\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain langchain_openai langsmith pandas langchain_experimental matplotlib langgraph langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import openai\n",
    "from litellm import completion\n",
    "from typing import List, Dict, Any\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Function for the OpenAI API key if it's not already set in the environment\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Initialize AgentNeo Session and Tracer\n",
    " Now, let's set up our AgentNeo session and tracer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project 'LangGraph_with_AgentNeo3 ' found.\n",
      "Tracing Started.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "# Import AgentNeo and Setup Tracing\n",
    "from agentneo import AgentNeo, Tracer, Evaluation, launch_dashboard \n",
    "\n",
    "# Initialize AgentNeo session\n",
    "neo_session = AgentNeo(session_name=\"langGraph_example1\")\n",
    "try:\n",
    "    neo_session.create_project(project_name=\"LangGraph_with_AgentNeo3 \")\n",
    "except:\n",
    "    neo_session.connect_project(project_name=\"LangGraph_with_AgentNeo3\")\n",
    "\n",
    "# Create tracer\n",
    "tracer = Tracer(session=neo_session)\n",
    "\n",
    "tracer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Define Agents and Tools\n",
    "Now, let's create our AI tools using langgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standalone PromptInstructions class\n",
    "@tracer.trace_agent(name=\"PromptInstructions\")\n",
    "class PromptInstructions(BaseModel):\n",
    "    \"\"\"Instructions on how to prompt the LLM.\"\"\"\n",
    "\n",
    "    objective: str\n",
    "    variables: List[str]\n",
    "    constraints: List[str]\n",
    "    requirements: List[str]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for managing prompt generation\n",
    "@tracer.trace_agent(name=\"PromptGenerator\")\n",
    "class PromptGenerator:\n",
    "    def __init__(self):\n",
    "        self.template = \"\"\"Your job is to get information from a user about what type of prompt template they want to create.\n",
    "\n",
    "        You should get the following information from them:\n",
    "\n",
    "        - What the objective of the prompt is\n",
    "        - What variables will be passed into the prompt template\n",
    "        - Any constraints for what the output should NOT do\n",
    "        - Any requirements that the output MUST adhere to\n",
    "\n",
    "        If you are not able to discern this info, ask them to clarify! Do not attempt to wildly guess.\n",
    "\n",
    "        After you are able to discern all the information, call the relevant tool.\"\"\"\n",
    "        \n",
    "        self.llm = ChatOpenAI(temperature=0.5)\n",
    "        self.llm_with_tool = self.llm.bind_tools([PromptInstructions])\n",
    "\n",
    "    @tracer.trace_tool(name=\"get message\")\n",
    "    def get_messages_info(self, messages):\n",
    "        return [SystemMessage(content=self.template)] + messages\n",
    "\n",
    "    @tracer.trace_tool(name=\"info chain\")\n",
    "    def info_chain(self, state):\n",
    "        messages = self.get_messages_info(state[\"messages\"])\n",
    "        response = self.llm_with_tool.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    @tracer.trace_tool(name=\"get prompt\")\n",
    "    def get_prompt_messages(self, messages: list):\n",
    "        tool_call = None\n",
    "        other_msgs = []\n",
    "        for m in messages:\n",
    "            if isinstance(m, AIMessage) and m.tool_calls:\n",
    "                tool_call = m.tool_calls[0][\"args\"]\n",
    "            elif isinstance(m, ToolMessage):\n",
    "                continue\n",
    "            elif tool_call is not None:\n",
    "                other_msgs.append(m)\n",
    "        prompt_system = \"\"\"Based on the following requirements, write a good prompt template:\n",
    "        \n",
    "        {reqs}\"\"\"\n",
    "        return [SystemMessage(content=prompt_system.format(reqs=tool_call))] + other_msgs\n",
    "\n",
    "    @tracer.trace_tool(name=\"prompt gen chain\")\n",
    "    def prompt_gen_chain(self, state):\n",
    "        messages = self.get_prompt_messages(state[\"messages\"])\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the PromptGenerator class\n",
    "prompt_generator = PromptGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the `Literal` type from the `typing` module, which allows defining specific literal values for type hints.\n",
    "\n",
    "from typing import Literal\n",
    "# Importing END which likely represents the end or termination of a process or a node\n",
    "from langgraph.graph import END\n",
    "\n",
    "@tracer.trace_tool(name=\"get state\")\n",
    "def get_state(state):\n",
    "    messages = state[\"messages\"]\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"add_tool_message\"\n",
    "    elif not isinstance(messages[-1], HumanMessage):\n",
    "        return END\n",
    "    return \"info\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# # Importing necessary components \n",
    "managing state graphs, saving memory, handling messages, and typing annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:agentneo.tracing.agent_tracer:Successfully updated and committed AgentCallModel with id 20\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "@tracer.trace_agent(name=\"workflow\")\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "memory = MemorySaver()\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Instantiate the PromptGenerator class\n",
    "prompt_generator = PromptGenerator()\n",
    "\n",
    "workflow.add_node(\"info\", prompt_generator.info_chain)\n",
    "workflow.add_node(\"prompt\", prompt_generator.prompt_gen_chain)\n",
    "\n",
    "@workflow.add_node\n",
    "def add_tool_message(state: State):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Prompt generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "workflow.add_conditional_edges(\"info\", get_state, [\"add_tool_message\", \"info\", END])\n",
    "workflow.add_edge(\"add_tool_message\", \"prompt\")\n",
    "workflow.add_edge(\"prompt\", END)\n",
    "workflow.add_edge(START, \"info\")\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Displaying a PNG image of a graph generated from a LangGraph instance using Mermaid visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAGwASIDASIAAhEBAxEB/8QAHQABAQACAwEBAQAAAAAAAAAAAAYEBQMHCAIBCf/EAFQQAAEEAQIDAgYKDgcHAwUAAAEAAgMEBQYRBxIhEzEUFSJBVpQIFhcyQlFVYdHTIyU2UmNxdHWBk5Wys9IzNTdUkbHUCSRDU2JytIKhwTSDkqOk/8QAGwEBAAIDAQEAAAAAAAAAAAAAAAECAwQFBgf/xAA1EQEAAQICBwQIBwEBAAAAAAAAAQIRA1ESFCExUnGRBDNBYQUTI2KSobHRFSIyweHw8VOB/9oADAMBAAIRAxEAPwD+qaIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIC4rFqGnH2k80cEfdzyODR/iVpclkbuTvy4rESeDPh5fC8i6MPbBuNwxgPR0pBB67hoILgdw13HW4e4GOTtrVBmVuEbOt5P/AHmU+c7Ofvyjf4LdgNhsBsFniimmL4k28o/uxNs2edVYUHY5ihv+Us+lfntqwnyxQ9aZ9K/TpfDE7nEUN/yZn0J7VsL8kUPVmfQp9j5/JOx+e2rCfLFD1pn0p7asJ8sUPWmfSv32rYX5IoerM+hPathfkih6sz6E9j5/I2Pz21YT5YoetM+lPbVhPlih60z6V++1bC/JFD1Zn0J7VsL8kUPVmfQnsfP5Gx+e2rCfLFD1pn0rLp5OnkN/BbcFnbqexka/b/ArF9q2F+SKHqzPoWLc0Jp29sZcLREgILZYoGxyNI7i17dnA/OCnsZ8Z+X8GxvkUvz29F8rrFqbJYHcNdNYPPYpbnYOe/vfF8bj5TNt3FzSSyoWOujR2xN4lEwIiLGgREQEREBERAREQEREBERAREQEREBERAREQEREBYWaykeEw1/IzAmKnXksPA87WNLj/ks1ajV+KfndJ5vGx/0lyjPXb+N8bmj/ADV8OKZriKt10xvcejMW/FaaoxzkOuys8ItyN3+yTv8ALkd18xcTsPMNh5lu1r9P5RmbwOOyEe4ZarxzAOGxHM0HYjzEb93mWq1VxN0foW1DW1JqvB6esTs7SKHK5GGs+Ru+3M0PcCRv03CnEmqa6pq33J3qVRXE3itjeF8OHbax2TzWRzFzwHH4vDwtls2ZQx0jtg97GgBrHElzh3LFPsguFwYHniTpAMJIDvHtXYkbbj+k+cf4qP4paj0vxk0xHj9MYrF8XhVtxzWINP6jqwW8YeV/ZWYpRIOR/MNgQ9p2Lup2IONDh1r7ILO4HiHw3xOO0Ln7uP1HQu3bVQ1oI7rXRNZyxNElhga5nMXSB3mczlJPMBTa54+Y7h3n5aeZ0xqeLDQSwQ2NTR49rsZA6UtDS6Tn5y0F7QXNYQDuCehXW9bQ/FTT9DgzqbJYx2t9T6ZgyVTL0mZGGOy6O01oid20hbHI+NsUbXncFx3I3UZxn4Fa54gniNHY0HFqfOZeZljAahv5iFsGKqtjiIpxxOcXRyh7JW8zWhrzJu54CD0Bd46Y+LibkdCUNOagzWbxzaklp9CvCa8MVjflldI+VoDW7eUPfd5a1wDttLwA41Z3itd1ZXzGk8lho8Zmb1OC5KyBtdscMojbA/lne8zgElxDeTcHZ3cFsuH2k81j+NXEjU1/GuoYzOUsMym+SaJ7nPhinEzCGOJBYZGjc9Dv5JIU3w7sZTgnm9dVdX0aeH0ff1DezdbV1vLVoanLaka9kD2PeHtkDi5vdynYbHqg72RQDfZB8LXnZvErSDjsTsM9V7h1P/EWbg+M/D7U+Vr4zDa601lslYJENOjl6800hALjysa8k7AE9B3AoK+WJk8T4pWNkje0tcx43Dge8EecKd0DM9mGmxsjzI/E2paAc4kkxsO8W5PUnsnR7k953KpVMaFHbx5y+N+zvZWeSMkbbtZywb/iPY7g+cEHzrYo7qq/l1/y60bpU6Ii11RERAREQEREBERAREQEREBERAREQEREBERAREQEREEqJW6FsWDPszTtiV0wn67UpHkueH+YRFxLubuaSd9hsRRGGteZHKWRWGOaCx+wcCD1BB+JZCmZOH2LZI+THvuYRzyS5uMtPhjJJ3J7IHk3J8/Lv3rY0qMTbXNpz335/wB2p37298W1P7rD+rH0LkhrQ19+yiZFv38jQN1OO0TOST7aM8N/MJ4un/61+e0if0pz36+L6pPV4fH8pTaM1SilvaRP6U579fF9UpPUOOymM4g6Rw0OqMz4FlI7rrBfLFz7xMY5nKez6dXHfoU9Xh8fyktGbtVfEsTJmFkjGyNPwXDcKZ9pE/pTnv18X1Se0if0pz36+L6pPV4fH8pLRmoPFtT+6w/qx9C+o6NaJ4eyvEx47nNYAQp32kT+lOe/XxfVL69oVafpeymYyUfTeKe89jDt8bY+UOHzHcfMmhhxvr+X+ItGbkyuYkzE8+HwswNkeRbusO7KTe5w3HQzbe9b5ujndNg7d47H18TQrUqkQgq1o2xRRt7mtaNgP8AlDH1cVTiqUq0NSrE3ljggYGMYPiDR0AWQqV1xMaNO76/35AiIsSBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQF17rEj3YeHQ3O/Y5Tb9VF867CXXusd/dh4dd39DlO/bf+ii/T/gg7CREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAXXmsf7YuHPUD7DlOhHU/Yol2GuvNZbe7Hw569exym3T8FEg7DREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQERfjnBjS5xAaBuSfMg/UUU7WGby4FjC42ica/rDYyFh7HzN8zwxrDs094JO5HmC+fHmsP7jg/Wpvq1uarieNo/9hNluvBvHb2dVvhv7IOvhb3DexLc0zYtVoQMq0G/HO1gilaOxPJzNDXcu599tv03Xrvx5rD+44P1qb6tdQ8QvY/zcSOMuj+I2SoYYZPTwP+7tnl7O2WnmhL/sf/DcSfPv0B6BNVrzjrBZ6GwF25ksFjbeQo+K79itHLYo9r2vg8jmgvj59hzcpJG+w3232Cz1EePNYf3HB+tTfVp481h/ccH61N9Wmq15x1gst0UU3UGrITzy4vEWGDqY4LsjXkf9JdHtv8x2HzhVGHy9fO46K7WLuyk5gWyN5Xsc0lrmuHmc1wII+MFYsTBrw4vO7ym5ZmoiLAgREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQFrNTOLdN5Ug7EVJSCP+wrZrWao+5rLfkk37hWTD/XHNMb05pcAaZxAAAHgcPQf9gWzWs0v9zWJ/JIf3AtmulifrnmTvEWp01qrF6vpWLeJsm1XgtTUpHmJ8fLNE8xyN2cATs5pG46HboSFyak1JjNIYK7mczdix2LpRmWezMdmsb/mTuQAB1JIA6rGhskWr0xqahrDCVstjHWHUbHN2brVWWtIdnFp3jla146g94G/eOi2iAsThqftVlB5hlrmw/8AuuWWsThr/VeV/O1z+KVNfc1c4/daN0q5ERcxUREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQFrNUfc1lvySb9wrZqY15qbGYfTGe8Jtt7WCk50kEIMszRJuxh7NgL9nOOw6f5LJh/rjmmN7A0v8Ac1ifySH9wLPsQizXliLnsEjSwujcWuG423BHUH5wsDS/3NYn8kh/cC2a6WJ+ueZO95B0jezuYr8NNOyau1HHVu6x1FjLVpuVldanq1xbMcT5nEuIAiaAd+Yd7S07EYfEulcynB/iTp7I57OXq+l9cY6nj7EuTm7c15pqDuzlkDuaUMNh5aXkkEMO+7QV6bx3CTSeJtYmxUxXZTYrIW8pTd4TKeys2RIJ5Ni/yuYSydDuBzdANhsyHCTSeUp56paxXa187kIMpkGeEyjt7MJiMcm4fu3YwRdG7A8vUHc76+jNkOs8vg7uquNEPDyTVGosRp3B6XgyEPi/Kyw3b88k8kJllsg9pIGNiHQnq5+7t+gVZ7G3VmT1jwno28vddlbda5dx4yTgAbscFmSGOY7dCXNY3cjvO5W/15wj0nxLmpz6hxZt2ajXxwWa9qarMxj9udnaQvY4sOw3aTsdu5UGA0/jdK4WliMRShx2MpxCGvVrs5WRsHcAFaItI2CxOGv9V5X87XP4pWWsThr/AFXlfztc/ilXr7mrnH7rRulXIiLmKiIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiLXZjUWM0+aQyV+Ck67ZjpVmzPDTPO/fkjYO9zjs47DzNce4EoNiin4dQZLJTRChg5o67b0lWzNk5PBiImDrNEwNcZA53RoPJv1O4G3N+UcDlZ34uzl85JLbpvndLBjIvBqlnn3DA9ji957Np6bPALt3Ee9DQz8hqTF4q/BRtX4Ir9iKSaClzgzzMjG73MjHlPDRtvsD3j4wtZFqHLZquH4rDy1YrGPfYr28uDAGTk7RxSQf0o++duG7DYd5IGzwOm8XpjH16OLow0qtdhjjZG3qAXFx6nqd3EuJJ6kknqVskE3NpS3mIpmZrM2rENmiyrPRx58DgEnfJLG5h7dpcem3akBvQdSSeTM4ahjNPZuSpTgryy0nMlljjAfIGRFrOZ3e7YdBvvsFQLjngZZgkhlaHxyNLHNPnBGxCtTOjVEiN0v8Ac1ifySH9wLZrRQ1M/pitDjo8LNnK1dgigt1LMTXvYAA3tGyvZs/bodiQdt+m/KPrxtn/AENyfrVP69deqmK6pqiqLT5x91rN2imW6qzD8tJjRozMGzHA2w49pW7MMc5zR9k7bl33a7yd99hvtsQsvxtn/Q3J+tU/r1X1fvR8VP3LN2i654i8aqvCbG0Mhq3CX8NRvXGUILE09VzDM8OLQ4tlPKNmndztmjzkKohzmbsQsli0hkZYpGhzHsuUi1wPUEET9Qnq/ej4qfuWb5YnDX+q8r+drn8UrUjOZ+bIMoR6QvwWZI3SsmtzwtrAAgHnljdJyndw8nYuI3IB5TtX6ZwftfxLarpfCJ3SSTzzcvKHySPL3kDc7N3cQBudgANzssWNMUYU0zMXmY3TE55G6G1REXNVEREBERAREQEREBERAREQEREBERARaCfWVN8rYMbFPmrMtWW1CKMZfBIGEjlNj+iY5zhyhrngkgnbZriOJ1LUOcjcLV2PBVLOOax1ei0SXK1p3V7mzu3YWtHkgdl1O7t+4INpnc/jdMYqfJ5e/WxmPg27SzblEcbd3BrQSem5c4ADzkgDqVrruosjNJfrYfCTWbVSeKEyZBxqVpA7q97JOVxeGN7+VpBOwB7yMzHaYxuLvWL0NYOyFmKGGe5KS+WVsQ2jDnHr03J/G4nvJK2qCesadyWVfYbkc3Myt4ayxWixbDVc2JndFI/mc5/Meri3k36DYDffY4nT2MwL7z8dQr0pL9l1y2+CMNdYmcADJIR1c7YNG58zQO4ALYIgIiICIiAiIgIi0+rprMOm7/gdS1dtSR9jHDSlbFLu8hnM17ujeXm5ubrsGk7HuQcOkzJcjyOTkZlK5vW3ltTKOAMDI9oW9mwe8Y8R9qAfKPaknb3rd8sXF46HEYypQr8/g9WFkEfaPL3crWho3cepOw7yspB5X9nrwP13x809ovTujKEFiBmSfPkLdq1HDFVbyBjHvBPO4eW8kMa47N7t9gbn2I/CjV/CHhXj8PqvVb8/zV4JIMbJVY12HeWkzVu2bK8TNa88oI2A5Dt0Ow7vU1piozB5nN4qCjVo0nTHIwdjY5nzOnc5873RnqwmbnduPJdz79/Mg3OUxFTNVhXuRdrG17ZW7OLXMe07tc1zSC0gjvBCwMJmJjZdiMrPVOciiM7m1WSMjlhL3NbIwP8AxDmaHO5C4Ak7tJ3a1mex09+pE6ras1bNaZlmPwaRre2Le+J/MCCx43adx033Ba4NcA2aLExN92UxlS2+pPQknibI6raaBLCSNyx4BI5geh2JHToSOqy0BERAREQEREBERAREQEREBEUuK0Gv4LBtbWdNSgRNoywOjdNLFO7ne9xd5cR7Nga3lAcOfm52vAAZTtTPv2BFhaZyYhyHgN2V7zBHWDW80jg5zfsu24bszcc5LSW8ruX4qaYsW2UJs9fdkrtV07uWrz1qrxIC3lfAHuEgaw8o7Qu6ku6HbahRBw06VfHVIatSCKrWhYI4oYWBjGNA2DWtHQAfEFzIiAiIgIiICIiAiIgIiICndT0fGuX07Vlxc12rHcNx9qOx2bKr4mOMbnt75N3OADe7fqfeqiU7LR8I4hVbj8XMRUxc0UWT8I2iHayxl8PZedx7CN3Oe4DYd5QUSIiAprJwirrzB3GV8cDZrWaUtmaTktH3kjI4hv5bfIkLh1I2BGw5lSqe1S1rclpmcw4x74slsJMg4Nkj5q8zCa5J/pTzcu3XdjnoKFERBN0KjNPastw16cMFHMc12Swbh5nXGtYxzGwuOwDo2Nd5HTdkhcN3bupFN68iZDh4ct2WMM2GssyDLOWl7KGqxu7LEvafAcK75wHHp5XleSSqRAREQERaTMa309p+14Nk85j6Fnbm7GxZYx+3x8pO+yvTRVXNqYvKbXbtFLe6po70oxPrkf0p7qmjvSjE+uR/SsurY3BPSU6M5KlFLe6po70oxPrkf0p7qmjvSjE+uR/SmrY3BPSTRnJUopb3VNHelGJ9cj+lPdU0d6UYn1yP6U1bG4J6SaM5KlFLe6po70oxPrkf0p7qmjvSjE+uR/SmrY3BPSTRnJstT6wwOiaEd7UWbx2BpSSiBlnJ2460bpCC4MDnkAuIa47d+zT8Sk+DnFDSeuNM4ipg9a0dVZGOhHNN/vUTrpbs0GSaFri5h3cAQR0JAXXXsrsVozjxwSzmm4tTYg5WIC/jCbrOlqMHkHvvhAuZ1+/38y6w/wBnvorTPBnhlbzeocvjcfqvPy801ezYYyarXYSI43AndpJ5nkfO34k1bG4J6SaM5Pa6KW91TR3pRifXI/pT3VNHelGJ9cj+lNWxuCekmjOSpRS3uqaO9KMT65H9Ke6po70oxPrkf0pq2NwT0k0ZyVKKW91TR3pRifXI/pT3VNHelGJ9cj+lNWxuCekmjOSpRS3uqaO9KMT65H9Ke6po70oxPrkf0pq2NwT0k0ZyVKKeocQtL5W1HWp6hxlmxI4MZFHbYXPce4Ab9T8wVCsVdFeHNq4tzRawiIqIEREBTtOhtxCy104qWLmxdOFuUdY3jn2ltEwti+CY92uL/hCZo+AqJTuPodlxAzl3xVLB22Oow+M3WOaOzySWj2TYvgGPtOYu+F2zR8BBRIiICnNaMcY8K9tbGWDHlax3ybg0Rgu5S+In/igO8kecnbzqjU7reF02Px3LXxlgsylJ+2VdysaBYZu5h/5oHWMed/KEFEiIgxMtj4stirlGeCC1BZhfDJBaZzxSNc0gte34TSDsR5wSsLR1+XJ6Tw1qeTHy2JacTpn4qXtahk5Bz9i/4TObflPxbLcKd0C0xaZihLcOzwexZriPA/8A0kYjsSMDAPgvaGgPb5pA8eZBRIiIMLNXHY7D3rTAC+CCSVoPxtaSP8lI6SqR19P0pAOaezCyeeZ3V80jmgue4nqSSf8A47gqfVX3MZj8jm/cKntM/c5ivySL9wLo4GzCnmt4NkiIrKiIiAiIgIiICIiAiIgIiICIiAiIg4blKvkasta1DHYrytLXxStDmuB7wQVy8O701/SVV08z55IZbFXtZSS9winfE0uJJJOzBuSdz3lfqxuF33Ij8vv/APmTKMXuJ5x9JT4KxERc1AiIgKcx1JsfEHO2xjbMLpsdRjORfNvDYDZLREbGfBdHzkud8ISs+9VGp3H0zHr7OWvFtiES4+jH4xfY5obHLJaPZtj+C6Pm3c74QlaPgoKJERAU5rqDt8TSHg+NscuVx7+XKP5I27W4jzMP/Nb3xjzvDB51Rqd11D2+HqN8Fx9vbKY93Jk5OSNu1yE87T/zW7c0Y88jWDzoKJERAU5oXZuOyMY8TAMyt7ycJ0ibzWHuPaDzTnm3l+OQvPnVGp3Rh3izI5sO7bKWemHHQeVvtN+H6+X86CiREQavVX3MZj8jm/cKntM/c5ivySL9wKh1V9zGY/I5v3Cp7TP3OYr8ki/cC6OD3M8/2W8GyXSenfZGy2+LGP0NnsDj8RdyT54qppagr5CeOSKN0nLZgYA6HmYxxB3cNxtvuu5rkBtVJ4WyvgdIxzBLGdnMJG24+cLzhob2PettL2+GsUvtRioaLvPkdNS7cWcoySGSGSeRxZsyXaTnLPLDnE+W0DrE32WVYfFLjrqbVujBk9LYC3jtHu1HQoQaqjywgnsNbkIopXMrtbzdi8h8e/Pu4O6t5SVy8f8AjpqXIcOOJw0Vp+34owEc+Os6riywpyw22bdr4PGG8zxGSA5/MzqHBvNsuSXgFxGoaGh4eY+/pixo2hmq+QoXbUliO+2tHeba7B7GsLOZuxaHg9QAC1u+45NZ8BuIr9K8R9GaZvaZm0tqy1bvwzZaSxFbpS2Xc8sW0bHNczn5i124I5uodtsqfmsPR1NxdUgJJJLGkk+founM5rzXVb2TdLS+MxtG9pp2nxdkinyPYEA2o2SWdhA4l7AS0R8wDgd+ZpVXc4yacwNqXG2odQOs1HGCQ1tMZOeMub0PLIyuWvHTo5pIPmKnszp3UWoOIun+JOiH4+WGXES4e5R1HDaov7B07ZRIxpi52vDmOHK9rQQR1V5nIazJeyXs04MrqKHR01nh1ism7GXNR+MGNlBZMIZZ46vIS+FkhILucHZpIaQFy6k9kZfxcurMlitFz5rR2k7T6eZzLcgyKVr4g11gwVy0mURB3lEvZuWuA32Why3sf9aWdMZzhzUymDi4c5fKS3JLj+28Z1601jwiasyMN7N27y9okLxs13vSQsnUfA/XQo680npzKYGvo3Wd2xbtW7om8PoC00C2yKNrezlDvLLS5zOXnO++wVfzCp4caktZvjnxOgGSsXMRDRwk9GB8znQxCWKw5zo2E7N59mk7Ab7DfuXYers97VtKZrNdh4V4tpTXOw5+TtOzjc/l5tjtvy7b7Hb4l1pV0lPwc4h5vVTZmz6NyWKx9CetXpWbeQgmqh8cJjjgjeXsc2Q8xIBBAPdutjm+IWF4lafzGlcQzNQ5PL4+zTryZHTuSqV2vfC8AvlkrhrB85PzDckBWibCWpeyI1bkMjpCnFw2ja/V9B9/Cukz7AC1kbJHiztCey8iQEcnaE7gbDrsynssMXidG4q9bxlfHakv5S5hziMrloadevZqPc2yZLbxyCNuw2cGlzi9gDdydt9ieEeYoZjg3bks0THo3D2MfkA2R+8sklWGJpi8jq3micTzcp2I6eYSL/Y8aoxtqDUOIv4Y6nxuqs1maVe92j6VmlkJCXwTEM5mP5Qw8zQ4Nc34QO6r+YIvZhUbenXS08LSu55ucr4F1evnYJMaJJonSxy+HsaWdmWscPec3OOUt3VLqTjlqPB6g0zpmHQ0U+q8vj58jJj7OcirxMbFIGGOGYsInlPMHBoDdm9SR122GZ03r7N8P5KF3C6CyOTtWz4ZirbbBx0lPlO0fOWFzpA7Y8xj226coPVdd5X2POt5eC+I4ftOks3FFXsNdeyzrXbYqd8r3wvpPDXOIha4NbzFpPI3qB5KfmFhxp9kJc4L3BNf07j58JHXbYksTair1rco/wCI2tVeOaZzB125m79w3XFxB9kXf09Pqr2saQdqqlpbGRZTMW35FtMRMkidMxsTSxxlcIm8597sCACT0Uzq72OWsclY1xWo5HT+Uh1ZiK+NnzucZM/IU+zqiB7Y2NaWua8gyb87eV0jiQ/br1lxugbpDWT4cvkcDHPa03Qq5fT8eYyNAZkxMcDFvHVe2zv1Y3lLHcp5XN2KiZmB3PrH2VeP05lKGIpwYKxlX4uvlLgy+pIMVXibM3mjjifM3mmeQCduRoALS4t5gF2hww4hY7itoPEaqxTJI6WRjc5scpaXRua9zHtJaS07PY4bgkHbcdCurq+g9YnUkXELReOwdJ2qMLQZldNapEsRpSxRnsix8THEOY2QxujLQDyjqPN3ZgoLlbC0Ysj4Kcg2FgsmjGWQGXYc5jaSSGl2+wJJ27yrxe+0ZyxuF33Ij8vv/wDmTLJWNwu+5Efl9/8A8yZWxe4nnH0qT4KxERc1AiIgKcx2PMXEHPXfFk8Inx1GIZF1jmiscklo9k2L4Do+fcu+F2rR8BUancdjOx1/nch4l8G8Ix1GHxx4XzeF9nJaPY9jv5HZdpzc+3l+EbfAQUSIiAp3Xdc2cNUYKuPubZTHP7PJSckTeW5C7naf+a3bmjHnkawedUSndd1/CcNUZ4Lj7m2Vxz+zyUnJG3luQu52nzyN25ox55GsHnQUSIiAp3RocG5vduHb9tLG3ifzjcdZ/wAP9/8AoVEpzRjeVub8jEM3ytg/ag779R1n/D/f/oQUaIiDV6q+5jMfkc37hU9pn7nMV+SRfuBVOZpuyOIvVGEB88EkQJ8xc0j/AOVH6SuRz4GlADyWasLILFd3R8MjWgOa4HqCD/iNiOhC6GBtwpjzW8G5REV1RERAREQEREBERAREQEREBERAREQFjcLvuRH5ff8A/MmX1ev1sZVks252V4IwXOkkdsAFz8PaE2P0nWZYhfXlllsWuykGzmCWd8oDgQCDs8bg9R3FRi7MCecfSU+CjREXNQIiICn6GPli13m7rsXHBBPj6UTMmJy59lzJLJdEY9/JEfO0h23ldsR8HpQKdoY0w8Qc3f8AFEcDbGMoQ+NhZ5n2SyW2exMXwBF2gcH/AAvCCPgIKJERAU7rqv4TiKTPBcfc2ymPf2eSk5I28tuJ3O0+eRu3Mwed7WDzqiU7rev4VQxsfguPufbSk/kyMnI1vLOx3Oz45G8vMwedwCCiREQFOaMbytzfkYhm+VsH7UHffqOs/wCH+/8A0KjU5oxvK3N+RiGb5WwftQd9+o6z/h/v/wBCCjREQFpsxovT+obAnyuCxuSnA5RLbqRyuA+LdwJW5RWprqom9M2k3Jb3K9F+iOD/AGdD/KnuV6L9EcH+zof5VUos2sY3HPWVtKc0t7lei/RHB/s6H+VPcr0X6I4P9nQ/yqpRNYxuOesmlOaW9yvRfojg/wBnQ/yp7lei/RHB/s6H+VVKJrGNxz1k0pzS3uV6L9EcH+zof5U9yvRfojg/2dD/ACqpRNYxuOesmlOaW9yvRfojg/2dD/KobgZw60tlODei7d7TuJv3J8TXkmtWKUUkkriwbuc7Y7k9++5/Gu4l1/7H4udwP0KXO5nHD1tz16nsx8fX/HqmsY3HPWTSnNt/cr0X6I4P9nQ/yp7lei/RHB/s6H+VVKJrGNxz1k0pzS3uV6L9EcH+zof5U9yvRfojg/2dD/KqlE1jG456yaU5pb3K9F+iOD/Z0P8AKnuV6L9EcH+zof5VUomsY3HPWTSnNLe5Xov0Rwf7Oh/lT3K9F+iOD/Z0P8qqUTWMbjnrJpTm0GO4f6XxFllijpzE07DHBzZYKMTHtI7iCG7grfoixVV1Vzeubomb7xERUQIiICnKuM7HiHk8gMMIvCMVUruzPhW5n7Oaw4V+x38ns+1c/n28rttvgqjU54t5OIfjBuF37XFdg/NeFd3LNzNrmH/1vfz/ADEfEgo0REBTmsa/hUmAi8Fx9oeNYXkX5OUs5WvfzxD4Uo5dwPi3PmVGpzUkHhWodKsNbH2BDdlsl1uTaaHlrSsEkDfhP3kDT8THu+ZBRoiICnNGN5W5vyMQzfK2D9qDvv1HWf8AD/f/AKFRqc0Y3lbm/IxDN8rYP2oO+/UdZ/w/3/6EFGiIgIiICIiAiIgIiICIiAuvvY9gt4G6EBj7IjDVQY+vk/Yx069f8V2CuvfY9MMfAzQbSx0Zbhqo5X94+xjoUHYSIiAiIgIiICIiAiIgIiICIiAp7IYvm11hMozEeEvio3Kj8mLXJ4KyR8D+Tse6TndC3yu9nZ/E8qhU7qzGixkNOZBmJGTs4/Ih8cnhfYGq2SKSF8u3dJs2Ujsz377jymhBRIiICnLkPhev8YTBjZWU8fYkMsj97sL5JIms7Nvmjc1kvM4+drAPOqNTmGjFvWOoLxixb+xZXoMs1X89scrXSujn+92Mwc1vfs/c++CCjREQFOaMbytzfkYhm+VsH7UHffqOs/4f7/8AQqNTmjG8rc35GIZvlbB+1B336jrP+H+//Qgo0REBERAREQEREBERAREQF197HxobwO0IAGgDDVhs3fb+jHdv1/x6rR+ym4ia14T8H8jq3Q2PxmTv4uVk1yvlIZZWGp1EjmNjkYeZrix25O3KH9POOq/9nrxS13xR4ZvdnsfiKOlcJHFicVJTrytsWXxtHO57nSuaQ0co6NG5J+LZB6xREQEREBERAREQEREBERAREQFpNa4Vuf0tkaZoRZSXs+2gqTzOhZJPGRJCC9vVn2RjDzDu23W7RBj4+14dQrWeVrO2jbJyteHgbjfYOHQ/jHQrIU3oqvHh4b+DirUaEGOsEVatKfn2rP8ALY5zD1jJcZG8vd5B5emwFIg/CQBuegU7oJomwHjHbDvdlJ5b4s4M81azFI8mCXnP9I4wCHmf3EgkeTsFy64vy0NNW21bGNrZC1y06bstuazp5SGRte1vVwLnAco2J7tx3jcU6cGOqQVasEdarAxsUUMLAxkbGjZrWtHQAAAADuQcyIiApzRjeVub8jEM3ytg/ag779R1n/D/AH/6FRqc0Y3lbm/IxDN8rYP2oO+/UdZ/w/3/AOhBRoiICIiAiIgLFyuRhw+LuX7HN2FWF88nINzytaXHYfHsFlKY4of2aat/NFv+C9ZcKmK8SmmfGYTEXmzUtZqLMRNtT5+zhnygPFPHQwObCPM0ulieXHYjc9NyOgA6L88TZz01zPq9H/TLcx+8b+IL6XS07bqY6R9k3aTxNnPTXM+r0f8ATJ4mznprmfV6P+mW7RNP3Y+GPsXTmR0tk8vj7VG7q7LWadqJ0E0MlagWyMcCHNI8G7iCQtToXhYOGmlqOnNNaky2LwtFpbBVZFTeGguLju51cuJJJO5JKuUTT92Phj7F2k8TZz01zPq9H/TJ4mznprmfV6P+mW7RNP3Y+GPsXaTxNnPTXM+r0f8ATL6Zjc/X8uLV9+eQdWsu1Kr4ificI4o3EficD84W5RNP3Y+GPsi7N0xnDqDEttPhFedskkE8IcXBkkbyxwBIG7d27g7DcEHYbrbKR4af1TlPztc/jOVcufj0xRi1U07rk7JERFgQIiICIiAiIgIiIJvKcuH1fjsjviKlbIRHHW57I7O5PI13NUjjf3Oa0vs+Q7zybtI8oOpFqdU4yxl8DbgpGo3Ihva05L1ft4YrDDzRPczoSGvDT0IPToQdiubT+dpanwdDLY6dlqjdhbPDMzcBzXDcdCAR+IgEdxAPRBrMnZ8YaxxeMit0SKcTshbpyxdpOWneOB7D3MHOJDzd55Nh05tqNTejrjM4cpm6+UiylC7aMdN0VXsuxihHZOj5j5Uv2Zs7w89NpBy9BzOpEBERAU5oxvK3N+RiGb5WwftQd9+o6z/h/v8A9Co1OaMbytzfkYhm+VsH7UHffqOs/wCH+/8A0IKNERAREQEREBTHFD+zTVv5ot/wXqnUxxQ/s01b+aLf8F62Oz99Rzj6rU74fUfvG/iC+l8x+8b+ILS66+4jUP5usfwnLblVvEXi7QOO0ppvTfsc8houWnBrrKSY6DJsx1jnnt0jTcbosMDjzNZsD5Q8hzWgbdy5sJpSPT/sY+ImucFUd7dY7edbBlm7vs04PD5mSiA98YEYe/Zu3lEu7zusekPZaLx5q/EaO0TqKjQ4YTwOoZbRecmzkWPtmeOeuyq01rM3lEdoZCWiQ+U7mcNyv3AcI9JT6k4Aslw0czNR6ctS5pskj3DKOZUrysNkF32ble4uAfuB0+IbNIewlpdY6wxWg9PWc3mrBq46u6Nj5GxueeaSRsbBs0E9XvaPm367DqvIOMxmEuZDh5pzUJhm0ti+IWpsTBXyM57JlaKK0IIXOcerQeVoaTsRs3qOixNe4fT1rhlxtxeJjrZHh7gc/hpsSObt6tKcug8PbA4khrGh7tw07N7R46AlNPYPcaLS6NxWn8HpunQ0vXo1cHAHCvDjeUQM3cXO5eXp74knbzkrdK4xOGn9U5T87XP4zlXKR4af1TlPztc/jOVctbtPfVc1qt4iItZUREQEREBERAREQFDXM6/AQ6ixb8rYtZPtYn021MVvJUjtyGKAADyJgyUSOc7pytG79gC43K0uV04/J6iwmVGXyNOPGGZzsfWmDK1wyM5B27dt3cm5LQCBzHcgkDYNpSrmpTggdK+d0UbWGWTbmeQNuY7ADc9/QBcyIgIiICnNGN5W5vyMQzfK2D9qDvv1HWf8P9/+hUandGM5W5vyMQzfKWD9qTvv1HWf8N99+hBRIiICIiAiIgKY4of2aat/NFv+C9U6muJrDJw31Wxo3c7E2wB8/YvWx2fvqOcfVanfBH7xv4gsPO4zx1hMhju07HwuvJX7Tl5uTmaW77bjfbfu3WZEQ6JhBBBAIIX0tuVUHwp4Nac4U6cwtOjisW7M0sbBj7Obr46OvYu9nG1he9w3d5RbvsXH8ZVfjMJjsLSdTx1CrQqOfJK6CrC2OMve4ue4taAN3Oc4k+ckk96zUURFhPYfh1pTT1fIQYrTGGxkGRaW3YqePiibaBBBEga0B4IJ99v3lZ8emcPDLi5Y8VRZJionQY97azAacbmhrmRHb7G0ta0EN2GzQPMtkiWHW+s+BmA1jntLW5aWNhxmJyNzJXMU/HRyQ5KWxBJE8yDoOYuk7QuLXFxHXqd1Z0dJ4TGYE4OnhsfUwpY6I42CqxlYsd75vZgcux3O4267raoloGvwOnsVpbGRY3C4yniMdFuY6lCuyCFm53OzGgAbkk93nWwRFIxOGn9U5T87XP4zlXKS4ajbE5M+Y5a7sR5/szh/nuq1avae+q5rVbxERayoiIgIiICIiAiIgIiICIiAiIgKc0W3lZmjyYlnNlbB+1Ltw7ygN5vw3Ty/nVGp3RLOWnlH9lioufKXD9qXczH7TObzSH/ndPsg8zgR5kFEiIgIiICIiAviaGOxE+KVjZYntLXseN2uB6EEecL7RBFnSGexjG1sVmKbqMYDYWZKo+WWNo7mmRsrecAbAEjm2HlFxJK+fEGsPlTB+oTfXK2RbmtYnjbpC10T4g1h8qYP1Cb65PEGsPlTB+oTfXK2RNaxMo6QXRPiDWHypg/UJvrlP8P7ur9eaHwWo22sLRblKcVsVnUpnmLnaHcpPajfbfv2Xay699j88HgzpOLbldVpio9vTyXROdE4dAB0LCO5NaxMo6QXZniDWHypg/UJvrk8Qaw+VMH6hN9crZE1rEyjpBdE+INYfKmD9Qm+uX0zTeq5vImzWKgjPQyVsfIZAP8Ap5pi0H5yCPmKtETWsTKOkfZF2HiMVXwmPhpVQ4Qx7nd7i5znElznOJ6kkkknzklZiItSZmqbzvQIiKAREQEREBERAREQEREBERAREQFOaBiczTpkdFionT3blj7Sneu8PsyvD9/PI4ODpD55C9bnKX4sVjLd2eaCtBWhfNJNakEcUbWtJLnvPRrQBuSe4blYGjMa/D6Sw9OatQqWIakTZocU0tqMk5QX9iD15Obfbfrttv1QblERAREQEREBERAREQEREBde8MHHAZvV+kp3/ZKWSkytNrid3U7r3zgjfzNnNqMAdwib3bgLsJS+r9MWr1yjncI6GHUWNDmw+Euc2G3A4jtK0pbuQ13KC14DjG9rXcrwHRvCoRaDSetKOrobDYY56GSqEMvYm81rLdJ532bI0EjY7Hle0uY8DdjnN2K36AiIgIiICIiAiIgIiICIiAiIgIiICIiAiLis2GVK8k0nNyRtLiGML3H5g0Akn4gASfMgn9byR3qtTAfamxNl5mwyUcswyR2agc022iMe+PY84HN5Ic5vNuPJdSrSYKCzdtTZi4XtFhrRTqT1WRS0oS1vOxzgXOc5728x6gABjeUFpc7doCIiAiIgIiICIiAiIgIiICIiCa1bw/xWr5a9ucTY/M1GltPM45/Y3awJBLWybHdhIBdG8OY7lHM12wWiOd1nohvLm8Z7ccW0n7aYKIR3I2eYy1C7yz37uhcST3RNC7CRBodK66wOtoJJMLk4brouk9frHYrn72WFwD43dPevaD8y3ymtWcOdPa1lhsZTHNdkIG8tfJ1ZH1rtcb77R2Iy2Rg367NcAfPutG7Ea80f1xOTra0xzeUCjnHCrdY0DY8lqJhZIfibJECT76TruA7BRQ+I4vYSzfhxmZjt6RzUp5WY7PxiAyu325YZg50M5+aKR5+MBVmVzFDBUnXMldrY6m17I3WLcrYow57gxjS5xA3c5zWgecuAHUoMxERAREQEREBERAREQEXFbtwUKs1mzNHXrQsdJLNK4NZG0DcucT0AABJJXHj8jUy2PrX6NqG5RsxNngtV5A+KWNwBa9rh0c0gggjoQUGSima+tGahpQT6XhZna1ypNYqZRkzRj3OaeVjXSjdxD3dzo2PHKC773m+pNJy5yKVuobjsjWt0GVLWHYxraBd3yvA5e0dzHydnvI5QAAN3Fwcl/V0ZlyFPD13ZzLUjAJqcLxG2PtT5JfI7yQA3d5AJdy7ENJc0O5YNPPs3xczE8WSmrXJLOPDYezbTa6PswAOY8z+Uv3eev2R4AaDstxDDHXhZFExsUTGhrGMGzWgdAAPMF9oCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiDEyuJo53HT4/JUq+RoWG8k1W3E2WKRvxOa4EEfMV4y9nXwi1lZ0PgtJcLsPqbJYzKW3WMjj6N10lGuyDZ0bDG8EsDnyBzWte2MGDfkJ5S32wiDoH2G+U4qHhw/B8VdP2MZksP2cNLJWZmOkvQEO2Dw0ny4+UAuPvg5vnDie5dSaxw2kYWSZa/HV59+zi2L5ZPj5Y2gud+gFa/iHrRui8IJomMmyNl/YVIZN+Uv2JLnbdeVoBJ7t+g3BIXQUz5bd2e7bmdbvzneazL79/zfMB5mjoB0AXd9H+jJ7XHrMSbU/Of7mndvdtzcesGxx7LF5mw0Ho5lZjQf0Pe0/+y4/d+xHyHnP1MP1q6oRehj0P2TKeqNLydr+79iPkPOfqYfrU937EfIec/Uw/WrqhE/B+yZT1NLydr+79iPkPOfqYfrU937EfIec/Uw/WrqhE/B+yZT1NLydsN4+4cnysLm2D4zBEf8pSqLTnFHTmp7LKta6a95/vat2J0Ejj8TeYAPP/AGkroVfE8EdmMxysbIw9dnDdY6/QvZqotTeJ53Lxkx/Z44/jDrnTtbRPDnTNi5g70Imy+TrzxtfL5RArAFwIHkhzj5+Zo8zgd97CzQur8bwdw+P4n4i3WzmmMhPWxDL8xeWVDFH2bgA8tPLzSRsJHktbs3Yb79g8Jtf2Ltgaey05sWWxmSlbkdu+aNu3Mx5Pvnt33Du9zd9+rXOd2kvH9p7PX2XEnDr/ANBERaoIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIg6M4zXX2dfV6rieyp41j2Df4Usrw7p+KFnVRivuOGHdU1Ji80B9gtV/AJHeZr2OdJGP0h8v/4j4115cndVqTzMgktPjY57YIeXnkIG/K3mIG57huQPjIX0b0dVTPZMOacv9RU5UUczX2Uc9oOgdSsBOxcXUNh8/S0vwa/ypIHtA1MPnLqH+qW562nz6T9lXW9/2QOcsWclfwuKbfxVO3JWix7MTkJrNxschY97LEcZhYSWu5WnfuHMQdwNvnuKGsK519extXDHF6TkD3RWmTdvaiFaOZ7dw4BjgHO2ds4HcDlG2532J4X5nTGXteINWPxunrV85CTFSY9kz2Pe/nlZHKXeQx536Fp25jsQsm7wt8LxvEOp4z5PbcHjn8H38E5qrYO7m8v3vN8Hv2+daMUdpmNszf8A8yndtztly3pTuoNfaj1jPqPH6Ur4uHG4qgx12zlRI580k0HaiKIMI5dmObu92/V23Kdiqrgp/Y9on8zVP4LVpLXB7J1Mjds4DVRw7MpShqZOCTHtsNndFF2TZWbvHZu5NgffA7Dp0Wwwdu/w50/iNMQaZzmoYsVSgqDJUm1I4p+SNo5g2Sw1w7u4j9J71ko9ZTiaeJE+Pn47LW8hfoo46+ygDT7QdSncbkB1Dp//AFLfafzFjN03z2cPewj2yFgr5Awl7hsDzDspHt267dTv0PTu33KcSmqbR9JQ3OOuPxudwt2Mlr4MhXO7Tt5LpAx4/Sx7h+leoF5r0riH6h1hhaDBuGWWXZv+mKFzXkn5i8Rt/wDWvSi8l6dmmcSiI32/z91/AREXmAREQEREBERAREQEREBERAREQEREBERAREQEREBERBgZ3B1NR4qxjr0ZkrTt2Ox2c094c0+YggEHzELoLVOisxo2eTwmtNexo/o8jWjLxy/hGt6sPxnbl+IjfYejEXT7F2/E7HMxTtpnwTzeTGZvHSN5m36zh8Ymb9K+vHFD+/Vv1zfpXqWxh6Fx/PPSrTv++kia4/8AuFxe1zE/JdL1dn0Lux6eo8cOev8ACLQ8v+OKH9+rfrm/Snjih/fq365v0r1B7XMT8l0vV2fQntcxPyXS9XZ9Cn8ew/8AnPX+C0PL/jih/fq365v0p44of36t+ub9K9Qe1zE/JdL1dn0J7XMT8l0vV2fQn49h/wDOev8ABaHl45nHgEm9WAH4Zv0rYYSld1TKIsJTkyhJ5TNF0gZ87pT5I2+IEn4gV6TZp/FxuDmY2o1w7iIGg/5LOADQAAAB0ACx4np3Z7PD2+c/x+5aEpw/0HFouhIZJRbylnY2bIGw6dzGDzMG5+ckkn4hWIi8vi4teNXOJiTeZBERYgREQEREBERB/9k=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Continuously prompts the user for input\n",
    "  streams responses from the graph, and handles fallback cached responses in case of input failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User (q/Q to quit): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Can you please provide more details on what type of prompt template you would like to create? Specifically, I would need to know the following information:\n",
      "\n",
      "- What is the objective of the prompt?\n",
      "- What variables will be passed into the prompt template?\n",
      "- Any constraints for what the output should NOT do?\n",
      "- Any requirements that the output MUST adhere to?\n",
      "\n",
      "Once I have this information, I can assist you in creating the prompt template.\n",
      "User (q/Q to quit): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I need more information in order to assist you. Could you please provide details on the following:\n",
      "\n",
      "1. What is the objective of the prompt template you want to create?\n",
      "2. What variables will be passed into the prompt template?\n",
      "3. Are there any constraints for what the output should NOT do?\n",
      "4. Are there any specific requirements that the output MUST adhere to?\n",
      "\n",
      "Once I have this information, I can help you create the prompt template.\n",
      "User (q/Q to quit): q\n",
      "AI: Byebye\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "import uuid\n",
    "\n",
    "cached_human_responses = [\"hi!\", \"rag prompt\", \"1 rag, 2 none, 3 no, 4 no\", \"red\", \"q\"]\n",
    "cached_response_index = 0\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user = input(\"User (q/Q to quit): \")\n",
    "    except:\n",
    "        user = cached_human_responses[cached_response_index]\n",
    "        cached_response_index += 1\n",
    "    print(f\"User (q/Q to quit): {user}\")\n",
    "    \n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "        \n",
    "    output = None\n",
    "    for output in graph.stream(\n",
    "        {\"messages\": [HumanMessage(content=user)]}, config=config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "        last_message.pretty_print()\n",
    "\n",
    "    if output and \"prompt\" in output:\n",
    "        print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Completed.\n",
      "Data saved to the database and JSON file.\n",
      "\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# Stop Tracing and Launch Dashboard\n",
    "tracer.stop()\n",
    "print(tracer.trace_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Metrics Evaluation\n",
    " Supported Metrics Goal Decomposition Efficiency (goal_decomposition_efficiency) Goal Fulfillment Rate (goal_fulfillment_rate) Tool Correctness Metric (tool_correctness_metric) Tool Call Success Rate Metric (tool_call_success_rate_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:17:55 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:17:57 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:17:57 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:17:58 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:17:58 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:18:01 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:18:01 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:18:04 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'metric_name': 'goal_decomposition_efficiency', 'score': 0.85, 'reason': \"The AI effectively decomposed the original goal into clear and relevant sub-tasks that cover all necessary aspects of creating a prompt template. Each sub-task is logically sequenced and independent, allowing for efficient execution. However, while the decomposition is comprehensive, there could be slight improvements in granularity, such as breaking down the final sub-task into more specific actions (e.g., drafting the template based on the gathered information). Overall, the decomposition is efficient and aligns well with the user's needs.\", 'result_detail': {'metric_name': 'goal_fulfillment_rate', 'config': {}, 'result': {'originalGoal': 'Assist the user in creating a prompt template by providing specific guidance on structure, objectives, variables, constraints, and requirements.', 'subtasks': ['Ask the user for details on the objective of the prompt template.', 'Inquire about the variables that will be passed into the prompt template.', 'Request information on any constraints for what the output should NOT do.', 'Clarify any specific requirements that the output MUST adhere to.', 'Once all information is gathered, assist the user in creating the prompt template.'], 'score': 0.85, 'reason': \"The AI effectively decomposed the original goal into clear and relevant sub-tasks that cover all necessary aspects of creating a prompt template. Each sub-task is logically sequenced and independent, allowing for efficient execution. However, while the decomposition is comprehensive, there could be slight improvements in granularity, such as breaking down the final sub-task into more specific actions (e.g., drafting the template based on the gathered information). Overall, the decomposition is efficient and aligns well with the user's needs.\"}}, 'config': {}, 'start_time': '2024-10-22T13:17:55.041093', 'end_time': '2024-10-22T13:18:01.992404', 'duration': 6.951311}, {'metric_name': 'goal_fulfillment_rate', 'score': 0.0, 'reason': \"The system response is '__end__', which does not provide any meaningful information or fulfill the user's query. The user query appears to be requesting some form of processing or response based on the provided arguments, but the system's response is simply an indication of the end of a process without any content or relevant output. Therefore, the goal fulfillment rate is 0.0, as the response does not address or satisfy the user's request in any way.\", 'result_detail': {'metric_name': 'goal_fulfillment_rate', 'config': {}, 'result': {'inputGoal': {'arg_0': 'self (instance)', 'arg_1': {'messages': [\"content='' additional_kwargs={} response_metadata={} id='f13c7e2e-f8f5-4ce7-91d8-86c54ad21298'\"]}}, 'finalResponse': '__end__', 'score': 0.0, 'reason': \"The system response is '__end__', which does not provide any meaningful information or fulfill the user's query. The user query appears to be requesting some form of processing or response based on the provided arguments, but the system's response is simply an indication of the end of a process without any content or relevant output. Therefore, the goal fulfillment rate is 0.0, as the response does not address or satisfy the user's request in any way.\"}}, 'config': {}, 'start_time': '2024-10-22T13:18:01.992526', 'end_time': '2024-10-22T13:18:04.143076', 'duration': 2.15055}, {'metric_name': 'tool_call_success_rate_metric', 'score': 1.0, 'reason': '{\"successful_calls\": 10, \"total_calls\": 10}', 'result_detail': {'metric_name': 'tool_call_success_rate', 'config': {}, 'result': {'score': 1.0, 'reason': '{\"successful_calls\": 10, \"total_calls\": 10}'}}, 'config': {}, 'start_time': '2024-10-22T13:18:04.143144', 'end_time': '2024-10-22T13:18:04.143205', 'duration': 6.1e-05}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'metric_name': 'goal_decomposition_efficiency',\n",
       "  'score': 0.85,\n",
       "  'reason': \"The AI effectively decomposed the original goal into clear and relevant sub-tasks that cover all necessary aspects of creating a prompt template. Each sub-task is logically sequenced and independent, allowing for efficient execution. However, while the decomposition is comprehensive, there could be slight improvements in granularity, such as breaking down the final sub-task into more specific actions (e.g., drafting the template based on the gathered information). Overall, the decomposition is efficient and aligns well with the user's needs.\",\n",
       "  'result_detail': {'metric_name': 'goal_fulfillment_rate',\n",
       "   'config': {},\n",
       "   'result': {'originalGoal': 'Assist the user in creating a prompt template by providing specific guidance on structure, objectives, variables, constraints, and requirements.',\n",
       "    'subtasks': ['Ask the user for details on the objective of the prompt template.',\n",
       "     'Inquire about the variables that will be passed into the prompt template.',\n",
       "     'Request information on any constraints for what the output should NOT do.',\n",
       "     'Clarify any specific requirements that the output MUST adhere to.',\n",
       "     'Once all information is gathered, assist the user in creating the prompt template.'],\n",
       "    'score': 0.85,\n",
       "    'reason': \"The AI effectively decomposed the original goal into clear and relevant sub-tasks that cover all necessary aspects of creating a prompt template. Each sub-task is logically sequenced and independent, allowing for efficient execution. However, while the decomposition is comprehensive, there could be slight improvements in granularity, such as breaking down the final sub-task into more specific actions (e.g., drafting the template based on the gathered information). Overall, the decomposition is efficient and aligns well with the user's needs.\"}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-10-22T13:17:55.041093',\n",
       "  'end_time': '2024-10-22T13:18:01.992404',\n",
       "  'duration': 6.951311},\n",
       " {'metric_name': 'goal_fulfillment_rate',\n",
       "  'score': 0.0,\n",
       "  'reason': \"The system response is '__end__', which does not provide any meaningful information or fulfill the user's query. The user query appears to be requesting some form of processing or response based on the provided arguments, but the system's response is simply an indication of the end of a process without any content or relevant output. Therefore, the goal fulfillment rate is 0.0, as the response does not address or satisfy the user's request in any way.\",\n",
       "  'result_detail': {'metric_name': 'goal_fulfillment_rate',\n",
       "   'config': {},\n",
       "   'result': {'inputGoal': {'arg_0': 'self (instance)',\n",
       "     'arg_1': {'messages': [\"content='' additional_kwargs={} response_metadata={} id='f13c7e2e-f8f5-4ce7-91d8-86c54ad21298'\"]}},\n",
       "    'finalResponse': '__end__',\n",
       "    'score': 0.0,\n",
       "    'reason': \"The system response is '__end__', which does not provide any meaningful information or fulfill the user's query. The user query appears to be requesting some form of processing or response based on the provided arguments, but the system's response is simply an indication of the end of a process without any content or relevant output. Therefore, the goal fulfillment rate is 0.0, as the response does not address or satisfy the user's request in any way.\"}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-10-22T13:18:01.992526',\n",
       "  'end_time': '2024-10-22T13:18:04.143076',\n",
       "  'duration': 2.15055},\n",
       " {'metric_name': 'tool_call_success_rate_metric',\n",
       "  'score': 1.0,\n",
       "  'reason': '{\"successful_calls\": 10, \"total_calls\": 10}',\n",
       "  'result_detail': {'metric_name': 'tool_call_success_rate',\n",
       "   'config': {},\n",
       "   'result': {'score': 1.0,\n",
       "    'reason': '{\"successful_calls\": 10, \"total_calls\": 10}'}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-10-22T13:18:04.143144',\n",
       "  'end_time': '2024-10-22T13:18:04.143205',\n",
       "  'duration': 6.1e-05}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute metrics\n",
    "from agentneo import Evaluation\n",
    "exe = Evaluation(session=neo_session, trace_id=tracer.trace_id)  \n",
    "exe.evaluate(metric_list=['goal_decomposition_efficiency', 'goal_fulfillment_rate', 'tool_call_success_rate_metric'])\n",
    "metric_results = exe.get_results()\n",
    "print(metric_results) \n",
    "metric_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dashboard launched successfully. Access it at: http://localhost:3000\n"
     ]
    }
   ],
   "source": [
    "# Launching dashboard\n",
    "neo_session.launch_dashboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
